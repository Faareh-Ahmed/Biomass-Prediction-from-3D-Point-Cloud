{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faareh-Ahmed/Biomass-Prediction-from-3D-Point-Cloud/blob/main/Bionet_Enhanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtoxgsZglvYR"
      },
      "source": [
        "# Drive Mounting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfpswmTWluxf",
        "outputId": "685860a9-96d5-408a-e3b5-213da2bbec80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgJzmkE-Rp-z"
      },
      "source": [
        "# Loading the DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b69OjaGgl7ff",
        "outputId": "c42541c3-fe82-4f1b-bfab-e0fec143eab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['20191002', '20190828', 'test_list.txt', 'train_list.txt', 'gcn_model_weights_0.001epoch50.pth', 'model2_weights.pth', 'model3_weights.pth', 'model4_weights.pth', 'pointNet_weights.pth', 'pointNet2_weights.pth', 'pointNet3_weights.pth', 'pointNet4_weights.pth']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to your folder\n",
        "folder_path = '/content/drive/MyDrive/TextFilesData'\n",
        "\n",
        "# List files in the folder to verify access\n",
        "print(os.listdir(folder_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5SEfIzZRwAT"
      },
      "source": [
        "# train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08s6ZQpKoDg7",
        "outputId": "1a6f220d-f2d0-4555-b2ef-1603f35d9e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c599a0d8ea2a>:8: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  df = pd.read_csv(train_list_path, delim_whitespace=True, header=None)\n",
            "<ipython-input-4-c599a0d8ea2a>:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  df_test=pd.read_csv(test_list_path, delim_whitespace=True, header=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  0                               1        2   3   4  5\n",
            "0    /20190828/Tony    e-w_20190828_001/1-5-1-b.pcd   380.60   3   1  3\n",
            "1    /20190828/Tony    e-w_20190828_001/1-7-1-b.pcd   309.27   4   1  3\n",
            "2    /20190828/Tony    e-w_20190828_001/1-9-1-b.pcd   303.53   5   1  3\n",
            "3    /20190828/Tony   e-w_20190828_001/1-11-1-b.pcd   410.57   6   1  3\n",
            "4    /20190828/Tony   e-w_20190828_001/1-13-1-b.pcd   204.15   7   1  3\n",
            "..              ...                             ...      ...  ..  .. ..\n",
            "199  /20191002/Tony  e-w_20191002_013/13-11-1-b.pcd  1177.20   6  13  4\n",
            "200  /20191002/Tony  e-w_20191002_013/13-13-1-b.pcd   941.60   7  13  4\n",
            "201  /20191002/Tony  e-w_20191002_013/13-14-1-b.pcd   568.00   8  13  4\n",
            "202  /20191002/Tony  e-w_20191002_013/13-17-1-b.pcd   853.00  11  13  4\n",
            "203  /20191002/Tony  e-w_20191002_013/13-18-1-b.pcd   686.00  12  13  4\n",
            "\n",
            "[204 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the train_list.txt file\n",
        "train_list_path = '/content/drive/MyDrive/TextFilesData/train_list.txt'\n",
        "test_list_path='/content/drive/MyDrive/TextFilesData/test_list.txt'\n",
        "\n",
        "# Read the file into a DataFrame\n",
        "df = pd.read_csv(train_list_path, delim_whitespace=True, header=None)\n",
        "df_test=pd.read_csv(test_list_path, delim_whitespace=True, header=None)\n",
        "\n",
        "# Display the DataFrame\n",
        "# df = df[:5]\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4BHIs9BFoSph",
        "outputId": "d8589e58-6ed0-4ac4-c6e1-ae098beceb99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0                              1       2  3  4  5\n",
              "0  /20190828/Tony   e-w_20190828_001/1-5-1-b.pcd  380.60  3  1  3\n",
              "1  /20190828/Tony   e-w_20190828_001/1-7-1-b.pcd  309.27  4  1  3\n",
              "2  /20190828/Tony   e-w_20190828_001/1-9-1-b.pcd  303.53  5  1  3\n",
              "3  /20190828/Tony  e-w_20190828_001/1-11-1-b.pcd  410.57  6  1  3\n",
              "4  /20190828/Tony  e-w_20190828_001/1-13-1-b.pcd  204.15  7  1  3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99d669f1-eba7-44e4-9ff4-61b744bad7f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/20190828/Tony</td>\n",
              "      <td>e-w_20190828_001/1-5-1-b.pcd</td>\n",
              "      <td>380.60</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/20190828/Tony</td>\n",
              "      <td>e-w_20190828_001/1-7-1-b.pcd</td>\n",
              "      <td>309.27</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/20190828/Tony</td>\n",
              "      <td>e-w_20190828_001/1-9-1-b.pcd</td>\n",
              "      <td>303.53</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/20190828/Tony</td>\n",
              "      <td>e-w_20190828_001/1-11-1-b.pcd</td>\n",
              "      <td>410.57</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/20190828/Tony</td>\n",
              "      <td>e-w_20190828_001/1-13-1-b.pcd</td>\n",
              "      <td>204.15</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99d669f1-eba7-44e4-9ff4-61b744bad7f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99d669f1-eba7-44e4-9ff4-61b744bad7f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99d669f1-eba7-44e4-9ff4-61b744bad7f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5b9f7b6c-6734-43ef-a25f-71ee191d4f7a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b9f7b6c-6734-43ef-a25f-71ee191d4f7a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5b9f7b6c-6734-43ef-a25f-71ee191d4f7a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 204,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"/20191002/Tony\",\n          \"/20190828/Tony\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 204,\n        \"samples\": [\n          \"e-w_20190828_002/2-18-1-b.pcd\",\n          \"e-w_20190828_002/2-7-1-b.pcd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 378.61038660283765,\n        \"min\": 149.78,\n        \"max\": 1341.8,\n        \"num_unique_values\": 201,\n        \"samples\": [\n          178.26,\n          276.52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 3,\n        \"max\": 12,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 13,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          12,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cxe8h4vprhl",
        "outputId": "aca6549c-847a-4209-c410-d4ae2c458aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 204 entries, 0 to 203\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       204 non-null    object \n",
            " 1   1       204 non-null    object \n",
            " 2   2       204 non-null    float64\n",
            " 3   3       204 non-null    int64  \n",
            " 4   4       204 non-null    int64  \n",
            " 5   5       204 non-null    int64  \n",
            "dtypes: float64(1), int64(3), object(2)\n",
            "memory usage: 9.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "VEMTH4hmp0FA",
        "outputId": "c448bebc-8965-4898-a5d2-9f010408ed40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        /20190828/Tonye-w_20190828_001/1-1-1-b.pcd\n",
              "1        /20190828/Tonye-w_20190828_001/1-3-1-b.pcd\n",
              "2       /20190828/Tonye-w_20190828_001/1-15-1-b.pcd\n",
              "3       /20190828/Tonye-w_20190828_001/1-16-1-b.pcd\n",
              "4        /20190828/Tonye-w_20190828_002/2-1-1-b.pcd\n",
              "                           ...                     \n",
              "97     /20191002/Tonye-w_20191002_012/12-16-1-b.pcd\n",
              "98      /20191002/Tonye-w_20191002_013/13-1-1-b.pcd\n",
              "99      /20191002/Tonye-w_20191002_013/13-3-1-b.pcd\n",
              "100    /20191002/Tonye-w_20191002_013/13-15-1-b.pcd\n",
              "101    /20191002/Tonye-w_20191002_013/13-16-1-b.pcd\n",
              "Name: 0, Length: 102, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/20190828/Tonye-w_20190828_001/1-1-1-b.pcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/20190828/Tonye-w_20190828_001/1-3-1-b.pcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/20190828/Tonye-w_20190828_001/1-15-1-b.pcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/20190828/Tonye-w_20190828_001/1-16-1-b.pcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/20190828/Tonye-w_20190828_002/2-1-1-b.pcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>/20191002/Tonye-w_20191002_012/12-16-1-b.pcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>/20191002/Tonye-w_20191002_013/13-1-1-b.pcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>/20191002/Tonye-w_20191002_013/13-3-1-b.pcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>/20191002/Tonye-w_20191002_013/13-15-1-b.pcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>/20191002/Tonye-w_20191002_013/13-16-1-b.pcd</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df[0]=df[0]+df[1]\n",
        "df[0]\n",
        "df_test[0]=df_test[0]+df_test[1]\n",
        "df_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "n7Df0T9qsfpZ",
        "outputId": "36c51b97-268a-4813-d7a3-c78ef0d72c2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        /20190828/Tonye-w_20190828_001/1-1-1-b.txt\n",
              "1        /20190828/Tonye-w_20190828_001/1-3-1-b.txt\n",
              "2       /20190828/Tonye-w_20190828_001/1-15-1-b.txt\n",
              "3       /20190828/Tonye-w_20190828_001/1-16-1-b.txt\n",
              "4        /20190828/Tonye-w_20190828_002/2-1-1-b.txt\n",
              "                           ...                     \n",
              "97     /20191002/Tonye-w_20191002_012/12-16-1-b.txt\n",
              "98      /20191002/Tonye-w_20191002_013/13-1-1-b.txt\n",
              "99      /20191002/Tonye-w_20191002_013/13-3-1-b.txt\n",
              "100    /20191002/Tonye-w_20191002_013/13-15-1-b.txt\n",
              "101    /20191002/Tonye-w_20191002_013/13-16-1-b.txt\n",
              "Name: 0, Length: 102, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/20190828/Tonye-w_20190828_001/1-1-1-b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/20190828/Tonye-w_20190828_001/1-3-1-b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/20190828/Tonye-w_20190828_001/1-15-1-b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/20190828/Tonye-w_20190828_001/1-16-1-b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/20190828/Tonye-w_20190828_002/2-1-1-b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>/20191002/Tonye-w_20191002_012/12-16-1-b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>/20191002/Tonye-w_20191002_013/13-1-1-b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>/20191002/Tonye-w_20191002_013/13-3-1-b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>/20191002/Tonye-w_20191002_013/13-15-1-b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>/20191002/Tonye-w_20191002_013/13-16-1-b.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df[0] = df[0].str.replace('.pcd', '.txt')\n",
        "df[0]\n",
        "df_test[0] = df_test[0].str.replace('.pcd', '.txt')\n",
        "df_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2P7sPiBs_j_"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=[1])\n",
        "df_test=df_test.drop(columns=[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKgFEenML8OT"
      },
      "source": [
        "### Loads the Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h248duCwUuP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Base directory\n",
        "base_dir = '/content/drive/MyDrive/TextFilesData'\n",
        "\n",
        "# Example to read point cloud data\n",
        "def load_point_cloud(file_path):\n",
        "    # Load the point cloud data from the .txt file\n",
        "    point_cloud = pd.read_csv(file_path, delimiter=' ', header=None)  # Adjust delimiter based on your file format\n",
        "    return point_cloud.values  # Convert to NumPy array or leave as DataFrame based on your needs\n",
        "\n",
        "# Create a DataFrame to store point clouds and biomass values\n",
        "data = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    full_path = base_dir + row[0]  # Construct full file path\n",
        "    point_cloud = load_point_cloud(full_path)  # Load point cloud data\n",
        "    biomass_value = row[2]  # Assuming biomass value is in the second column\n",
        "\n",
        "    data.append([full_path, point_cloud, biomass_value])  # Store all in a list\n",
        "\n",
        "# Convert list to DataFrame\n",
        "df_point_clouds = pd.DataFrame(data, columns=[\n",
        "    \"file_path\", \"point_cloud\", \"biomass\"])\n",
        "\n",
        "# Now you can access them easily:\n",
        "# df_point_clouds[\"point_cloud\"][0]# -> First point cloud\n",
        "# df_point_clouds[\"biomass\"].mean() -> Compute average biomass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3xceZ5AwfJT",
        "outputId": "c9aaa084-d379-4f70-9015-3e9b914d7519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 204 entries, 0 to 203\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   file_path    204 non-null    object \n",
            " 1   point_cloud  204 non-null    object \n",
            " 2   biomass      204 non-null    float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 4.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df_point_clouds.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMQCnC8FCA6W"
      },
      "source": [
        "# Load Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nRd9sHUyBy-"
      },
      "source": [
        "# loading Test data as a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvcolvdQxRqF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Base directory\n",
        "base_dir = '/content/drive/My Drive/TextFilesData'\n",
        "\n",
        "# Example to read point cloud data\n",
        "def load_point_cloud_test(file_path):\n",
        "    # Load the point cloud data from the .txt file\n",
        "    test_point_cloud = pd.read_csv(file_path, delimiter=' ', header=None)  # Adjust delimiter based on your file format\n",
        "    return test_point_cloud.values  # Convert to NumPy array or leave as DataFrame based on your needs\n",
        "\n",
        "# Create a DataFrame to store point clouds and biomass values\n",
        "test_data = []\n",
        "\n",
        "for i, row in df_test.iterrows():\n",
        "    full_path = base_dir + row[0]  # Construct full file path\n",
        "    test_point_cloud = load_point_cloud_test(full_path)  # Load point cloud data\n",
        "    test_biomass_value = row[2]  # Assuming biomass value is in the second column\n",
        "\n",
        "    test_data.append([full_path, test_point_cloud, test_biomass_value])  # Store all in a list\n",
        "\n",
        "# Convert list to DataFrame\n",
        "df_test_point_clouds = pd.DataFrame(test_data, columns=[\"file_path\", \"point_cloud\", \"biomass\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JifxA1vuyNbB",
        "outputId": "47024fec-815c-4934-ec52-15dec38dd992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 102 entries, 0 to 101\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   file_path    102 non-null    object \n",
            " 1   point_cloud  102 non-null    object \n",
            " 2   biomass      102 non-null    float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 2.5+ KB\n"
          ]
        }
      ],
      "source": [
        "df_test_point_clouds.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zztmBot42CGG"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9sFORB82EpK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Preprocess point cloud: remove headers, handle NaNs, center, and scale\n",
        "def preprocess_point_cloud(point_cloud):\n",
        "    # Convert point cloud to numerical values, skipping header rows\n",
        "    point_cloud = np.array(point_cloud[2:], dtype=np.float32)\n",
        "\n",
        "    # Remove rows with NaN values\n",
        "    point_cloud = point_cloud[~np.isnan(point_cloud).any(axis=1)]\n",
        "\n",
        "    # Center the data\n",
        "    X, Y, Z = point_cloud[:, 0], point_cloud[:, 1], point_cloud[:, 2]\n",
        "    X_centered = X - np.mean(X)\n",
        "    Y_centered = Y - np.mean(Y)\n",
        "    Z_centered = Z - np.mean(Z)\n",
        "\n",
        "    # Apply scaling\n",
        "    X_scaled = X_centered / 15.0\n",
        "    Y_scaled = Y_centered / 15.0\n",
        "    Z_scaled = Z_centered / 20.0\n",
        "\n",
        "    # Reconstruct the point cloud\n",
        "    point_cloud[:, 0] = X_scaled\n",
        "    point_cloud[:, 1] = Y_scaled\n",
        "    point_cloud[:, 2] = Z_scaled\n",
        "\n",
        "    return point_cloud\n",
        "\n",
        "# Pad point clouds to a fixed size\n",
        "def pad_point_cloud(point_cloud, max_points=1024):\n",
        "    num_points = point_cloud.shape[0]\n",
        "    if num_points < max_points:\n",
        "        padding = max_points - num_points\n",
        "        point_cloud = np.pad(point_cloud, ((0, padding), (0, 0)), mode='constant', constant_values=0)\n",
        "    else:\n",
        "        point_cloud = point_cloud[:max_points, :]\n",
        "    return point_cloud\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_data_with_padding(df, max_points=1024):\n",
        "    point_clouds = []\n",
        "    biomass_values = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        point_cloud = preprocess_point_cloud(row['point_cloud'])\n",
        "        point_cloud = pad_point_cloud(point_cloud, max_points)\n",
        "        point_clouds.append(point_cloud)\n",
        "        biomass_values.append(row['biomass'])\n",
        "\n",
        "    return np.array(point_clouds), np.array(biomass_values)\n",
        "\n",
        "# Load point clouds and biomass data\n",
        "point_clouds, biomass_values = load_data_with_padding(df_point_clouds)\n",
        "\n",
        "# Load preprocessed train and test data\n",
        "X_train, y_train = load_data_with_padding(df_point_clouds)\n",
        "X_test, y_test = load_data_with_padding(df_test_point_clouds)\n",
        "\n",
        "# Custom Dataset class\n",
        "class BiomassDataset(Dataset):\n",
        "    def __init__(self, point_clouds, biomass_values):\n",
        "        self.point_clouds = point_clouds\n",
        "        self.biomass_values = biomass_values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.point_clouds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.point_clouds[idx][:, :3], dtype=torch.float32), torch.tensor(self.biomass_values[idx], dtype=torch.float32)\n",
        "\n",
        "# DataLoader for training and testing\n",
        "train_dataset = BiomassDataset(X_train, y_train)\n",
        "test_dataset = BiomassDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=24, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=24, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kRnmVOzWA8H"
      },
      "source": [
        "# BIONET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3fwNphhwheF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.checkpoint import checkpoint # For gradient checkpointing\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "class PointTransformerLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Completed Point Transformer Layer based on common implementations.\n",
        "    Applies self-attention to point features.\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "\n",
        "        # Position embedding MLP (maps relative position to a feature)\n",
        "        self.pos_mlp = nn.Sequential(\n",
        "            nn.Linear(3, channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels, channels)\n",
        "        )\n",
        "\n",
        "        # Query, Key, Value MLPs\n",
        "        self.query_mlp = nn.Linear(channels, channels)\n",
        "        self.key_mlp = nn.Linear(channels, channels)\n",
        "        self.value_mlp = nn.Linear(channels, channels)\n",
        "\n",
        "        # Output MLP\n",
        "        self.out_mlp = nn.Sequential(\n",
        "            nn.Linear(channels, channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels, channels)\n",
        "        )\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(channels)\n",
        "        self.norm2 = nn.LayerNorm(channels)\n",
        "\n",
        "    def forward(self, x_features):\n",
        "        # x_features: (batch_size, N, channels) - Assumes features already incorporate spatial info or are global\n",
        "        # For a true Point Transformer, this would usually take xyz and features\n",
        "        # This implementation assumes x_features are point-wise features.\n",
        "\n",
        "        # Simplified: Treat x_features as input, apply self-attention\n",
        "        # This is a basic Transformer block applied to point features, not the full Point Transformer\n",
        "        # which uses relative position encoding in attention.\n",
        "\n",
        "        residual = x_features\n",
        "        x = self.norm1(x_features)\n",
        "\n",
        "        # Linear projections\n",
        "        q = self.query_mlp(x) # (B, N, channels)\n",
        "        k = self.key_mlp(x)   # (B, N, channels)\n",
        "        v = self.value_mlp(x) # (B, N, channels)\n",
        "\n",
        "        # Self-attention\n",
        "        # (B, N, channels) @ (B, channels, N) -> (B, N, N)\n",
        "        attn_weights = torch.bmm(q, k.transpose(1, 2)) / (self.channels ** 0.5)\n",
        "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
        "\n",
        "        # (B, N, N) @ (B, N, channels) -> (B, N, channels)\n",
        "        attn_output = torch.bmm(attn_weights, v)\n",
        "\n",
        "        # Add residual and apply output MLP\n",
        "        x = residual + attn_output\n",
        "        residual = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.out_mlp(x)\n",
        "        out = residual + x\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG2WLQibTbdm"
      },
      "outputs": [],
      "source": [
        "class PointNet2SetAbstraction(nn.Module):\n",
        "    \"\"\"Placeholder for PointNet++ Set Abstraction Layer.\"\"\"\n",
        "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):\n",
        "        super().__init__()\n",
        "        self.npoint = npoint\n",
        "        self.out_channels = mlp[-1] # Output feature dimension from the mlp list\n",
        "\n",
        "        # MLP for processing existing features (if points is not None)\n",
        "        # The input dimension should match the dimension of 'points'\n",
        "        # This is tricky without knowing the exact structure. Assume it's adaptable.\n",
        "        # (which is 'in_channel' if we follow PointNet++ convention closely,\n",
        "        # as 'in_channel' often includes coordinates).\n",
        "        self.mlp_process_features = nn.Sequential(\n",
        "            nn.Linear(in_channel, self.out_channels), # Example: Use in_channel directly\n",
        "            nn.ReLU()\n",
        "            # Add more layers based on the 'mlp' list if needed\n",
        "        )\n",
        "\n",
        "        # MLP for creating features from xyz (if points is None)\n",
        "        self.mlp_create_features = nn.Sequential(\n",
        "            nn.Linear(3, self.out_channels // 2), # Input is 3 for xyz\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.out_channels // 2, self.out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, xyz, points):\n",
        "        # xyz: (batch_size, N, 3)\n",
        "        # points: (batch_size, N, D) -> input features or None\n",
        "\n",
        "        # Placeholder sampling: just take the first npoint points\n",
        "        if self.npoint is not None and xyz.size(1) > self.npoint:\n",
        "            # Use random sampling for slightly better coverage than just taking first N\n",
        "            indices = torch.randperm(xyz.size(1), device=xyz.device)[:self.npoint]\n",
        "            indices = indices.unsqueeze(0).repeat(xyz.size(0), 1) # Shape (B, npoint)\n",
        "            new_xyz = torch.gather(xyz, 1, indices.unsqueeze(-1).expand(-1, -1, 3))\n",
        "        else:\n",
        "            new_xyz = xyz\n",
        "            indices = torch.arange(xyz.size(1)).unsqueeze(0).repeat(xyz.size(0), 1).to(xyz.device)\n",
        "\n",
        "        if points is not None:\n",
        "            # If features exist, sample them\n",
        "            sampled_points = torch.gather(points, 1, indices.unsqueeze(-1).expand(-1, -1, points.size(-1)))\n",
        "\n",
        "            # Process sampled features using mlp_process_features\n",
        "            # Ensure input dimension matches. If in_channel included xyz dim, concat here.\n",
        "            # Assuming self.mlp_process_features handles the dimension D of sampled_points\n",
        "            # This might require adjusting self.mlp_process_features input layer dynamically or making assumptions.\n",
        "            # Let's assume in_channel == D for simplicity in placeholder.\n",
        "            try:\n",
        "                 new_points = self.mlp_process_features(sampled_points)\n",
        "            except RuntimeError as e:\n",
        "                 print(f\"Error in PointNet2SetAbstraction mlp_process_features: {e}\")\n",
        "                 print(f\"Input shape: {sampled_points.shape}, Expected input dim based on in_channel: {self.mlp_process_features[0].in_features}\")\n",
        "                 # Fallback: create features from xyz instead\n",
        "                 new_points = self.mlp_create_features(new_xyz)\n",
        "\n",
        "        else:\n",
        "            # If no input features, create them from sampled xyz coordinates\n",
        "            # print(\"PointNet2SetAbstraction: Input 'points' is None, creating features from xyz.\") # Reduce verbosity\n",
        "            new_points = self.mlp_create_features(new_xyz)\n",
        "\n",
        "        return new_xyz, new_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCIa0YWtwp00"
      },
      "outputs": [],
      "source": [
        "# helper functions\n",
        "\n",
        "def estimate_normals(points):\n",
        "    return torch.zeros_like(points)\n",
        "\n",
        "def point_density_histogram(points, bins=10):\n",
        "    batch_size = points.size(0)\n",
        "    return torch.ones(batch_size, bins, device=points.device) / bins\n",
        "\n",
        "def cosine_similarity(x, y, dim=-1, eps=1e-8):\n",
        "    numerator = torch.sum(x * y, dim=dim)\n",
        "    denominator = torch.linalg.norm(x, dim=dim) * torch.linalg.norm(y, dim=dim)\n",
        "    return numerator / (denominator + eps)\n",
        "\n",
        "def KLDivergence(p, q, eps=1e-8):\n",
        "    p_safe = p + eps\n",
        "    return torch.sum(p * torch.log(p_safe / (q + eps) + eps), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI86Ytl7wwK3"
      },
      "outputs": [],
      "source": [
        "class EarthMoverDistance(nn.Module):\n",
        "    def __init__(self): super().__init__()\n",
        "    def forward(self, p1, p2): return chamfer_distance(p1, p2)\n",
        "\n",
        "# class Ranger(optim.Optimizer):\n",
        "#     def __init__(self, params, lr=1e-3, **kwargs):\n",
        "#         self._optimizer = optim.Adam(params, lr=lr, **kwargs)\n",
        "#         self.param_groups = self._optimizer.param_groups\n",
        "#         self.state = self._optimizer.state\n",
        "#     def zero_grad(self): self._optimizer.zero_grad()\n",
        "#     def step(self, closure=None): self._optimizer.step(closure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzk2FVz9YX3Z"
      },
      "outputs": [],
      "source": [
        "class Ranger(optim.Optimizer):\n",
        "    def __init__(self, params, lr=1e-3, alpha=0.5, k=6, N_sma_threshhold=5,\n",
        "                 betas=(.95, 0.999), eps=1e-5, weight_decay=0, use_gc=True, gc_conv_only=False):\n",
        "        # k recent averaging and k intervals\n",
        "        if alpha < 0 or alpha > 1:\n",
        "            raise ValueError('Invalid slow update rate: {}'.format(alpha))\n",
        "        if lr < 0:\n",
        "            raise ValueError('Invalid Learning Rate: {}'.format(lr))\n",
        "        if eps < 0:\n",
        "            raise ValueError('Invalid eps: {}'.format(eps))\n",
        "\n",
        "        defaults = dict(lr=lr, alpha=alpha, k=k, N_sma_threshhold=N_sma_threshhold,\n",
        "                        betas=betas, eps=eps, weight_decay=weight_decay, use_gc=use_gc, gc_conv_only=gc_conv_only)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "        # Lookahead and Gradient Centralization are handled internally\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super().__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Ranger does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if 'step' not in state:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['slow_buffer'] = None # Lookahead buffer\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "                # Lookahead implementation\n",
        "                if state['slow_buffer'] is None:\n",
        "                    state['slow_buffer'] = torch.empty_like(p.data)\n",
        "                    state['slow_buffer'].copy_(p.data)\n",
        "\n",
        "                # GC operation for Conv layers and FC layers\n",
        "                if group['use_gc'] and grad.dim() > 1:\n",
        "                     if group['gc_conv_only'] and grad.dim() == 4:\n",
        "                         grad.add_(-grad.mean(dim=tuple(range(1, grad.dim())), keepdim=True))\n",
        "                     elif not group['gc_conv_only']:\n",
        "                         grad.add_(-grad.mean(dim=tuple(range(1, grad.dim())), keepdim=True))\n",
        "\n",
        "                # Decay the first and second moment running averages\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
        "\n",
        "                # Correct bias\n",
        "                bias_correction1 = torch.tensor(1 - beta1 ** state['step'])\n",
        "                bias_correction2 = torch.tensor(1 - beta2 ** state['step'])\n",
        "\n",
        "                # Apply weight decay\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(p_data_fp32, alpha=-group['weight_decay'] * group['lr'])\n",
        "\n",
        "                # AdamW style update\n",
        "                denom = (exp_avg_sq.sqrt() / bias_correction2.sqrt()).add_(group['eps'])\n",
        "                p_data_fp32.addcdiv_(exp_avg, denom, value=-group['lr'] / bias_correction1)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "                # Lookahead update\n",
        "                if state['step'] % group['k'] == 0:\n",
        "                    slow_p = state['slow_buffer']\n",
        "                    slow_p.mul_(group['alpha']).add_(p.data, alpha=1.0 - group['alpha'])\n",
        "                    p.data.copy_(slow_p)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsxEmlbywytr"
      },
      "outputs": [],
      "source": [
        "class DualAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Completed Dual Attention Module.\n",
        "    Combines spatial attention (simplified self-attention) and channel attention.\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "\n",
        "        # Spatial Attention (Simplified: MLP-based attention weights per point)\n",
        "        self.spatial_att = nn.Sequential(\n",
        "            nn.Linear(channels, channels // 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // 4, channels),\n",
        "            nn.Sigmoid() # Use sigmoid to get attention weights\n",
        "        )\n",
        "\n",
        "        # Channel Attention (Global Average Pooling + MLP)\n",
        "        self.channel_att = nn.Sequential(\n",
        "            nn.Linear(channels, channels // 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // 4, channels),\n",
        "            nn.Sigmoid() # Use sigmoid to get attention weights\n",
        "        )\n",
        "\n",
        "    def forward(self, x_features):\n",
        "        # x_features: (batch_size, N, channels)\n",
        "\n",
        "        # Spatial Attention\n",
        "        spatial_weights = self.spatial_att(x_features) # (B, N, channels)\n",
        "        spatial_out = x_features * spatial_weights # Apply spatial attention\n",
        "\n",
        "        # Channel Attention\n",
        "        # Global Average Pooling across points\n",
        "        global_features = x_features.mean(dim=1, keepdim=True) # (B, 1, channels)\n",
        "        channel_weights = self.channel_att(global_features) # (B, 1, channels)\n",
        "        channel_out = x_features * channel_weights # Apply channel attention\n",
        "\n",
        "        # Combine spatial and channel attention outputs (e.g., element-wise sum or concatenation)\n",
        "        # Here, using element-wise sum as a simple combination\n",
        "        out = spatial_out + channel_out\n",
        "\n",
        "        # Optionally add a residual connection\n",
        "        out = out + x_features\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phGRKJAuw4NJ"
      },
      "outputs": [],
      "source": [
        "class CompletionDecoder(nn.Module):\n",
        "     def __init__(self, feature_dim=1024, num_out_points=2048):\n",
        "         super().__init__()\n",
        "         self.num_out_points = num_out_points\n",
        "         # Consider adding BatchNorm layers\n",
        "         self.decoder = nn.Sequential(\n",
        "             nn.Linear(feature_dim, 1024),\n",
        "             nn.BatchNorm1d(1024), # Added BN\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.Linear(1024, self.num_out_points * 3)\n",
        "         )\n",
        "\n",
        "     def forward(self, global_feature):\n",
        "         flat_output = self.decoder(global_feature)\n",
        "         completed_cloud = flat_output.view(global_feature.size(0), self.num_out_points, 3)\n",
        "         return completed_cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xVykrizw8Oh"
      },
      "outputs": [],
      "source": [
        "class PointFeatureExtractor(nn.Module):\n",
        "    # Consider adding BatchNorm, Dropout\n",
        "    def __init__(self, input_dim=3, feature_dim=1024, use_dual_attention=True):\n",
        "        super().__init__()\n",
        "        self.mlp1 = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.mlp2 = nn.Linear(128, feature_dim)\n",
        "        self.use_dual_attention = use_dual_attention\n",
        "        if use_dual_attention: self.attn = DualAttention(feature_dim) #\n",
        "\n",
        "    def forward(self, x): # x shape: B, M, 3 (or input_dim)\n",
        "        features = self.mlp1(x) # B, M, 128\n",
        "        features = self.mlp2(features) # B, M, feature_dim\n",
        "        # if self.use_dual_attention: features = self.attn(features)\n",
        "        pooled_features, _ = torch.max(features, 1) # B, feature_dim\n",
        "        return pooled_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ki3zGYPw_zo"
      },
      "outputs": [],
      "source": [
        "class ProjectionModule(nn.Module):\n",
        "    def __init__(self, feature_dim=1024, img_size=64):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, 1), nn.ReLU(), nn.Conv2d(32, 64, 3, 1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, 1), nn.ReLU(), nn.Conv2d(128, 256, 3, 1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.AdaptiveAvgPool2d(1))\n",
        "        self.fc = nn.Linear(256, feature_dim)\n",
        "\n",
        "    def _render_bev_image(self, points):\n",
        "        img_dtype = points.dtype  # Get the data type of the points tensor\n",
        "        batch_size = points.size(0); device = points.device\n",
        "        img = torch.zeros((batch_size, 1, self.img_size, self.img_size), device=device)\n",
        "        coords = ((points[:, :, :2] + 1) / 2 * (self.img_size - 1)).round().long()\n",
        "        coords = torch.clamp(coords, 0, self.img_size - 1)\n",
        "        z_values = points[:, :, 2]\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            img_indices = coords[b, :, 1] * self.img_size + coords[b, :, 0]\n",
        "            if hasattr(torch, \"scatter_reduce\"):\n",
        "                 img.view(batch_size, -1)[b].scatter_reduce_(0, img_indices, z_values[b].to(img.dtype), reduce=\"amax\", include_self=False)\n",
        "            else:\n",
        "                 unique_indices = torch.unique(img_indices)\n",
        "                 for idx in unique_indices:\n",
        "                      mask = (img_indices == idx)\n",
        "                      if mask.any(): img.view(batch_size, -1)[b, idx] = torch.max(z_values[b, mask])\n",
        "            return img\n",
        "\n",
        "    def forward(self, points):\n",
        "        bev_image = self._render_bev_image(points)\n",
        "        cnn_features = self.conv(bev_image) # B, 256, 1, 1\n",
        "        flat_features = cnn_features.view(bev_image.size(0), -1) # B, 256\n",
        "        vp = self.fc(flat_features) # B, feature_dim\n",
        "        return vp\n",
        "\n",
        "class PointAugment(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.transformer = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 6))\n",
        "    def forward(self, x): return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djCEIICuxMri"
      },
      "outputs": [],
      "source": [
        "class MultiScaleCompletionEncoder(nn.Module):\n",
        "    \"\"\"Encoder using PointNet++ and Point Transformer concepts.\"\"\"\n",
        "    def __init__(self, feature_dim=1024):\n",
        "        super().__init__()\n",
        "        self.sa1 = PointNet2SetAbstraction(npoint=512, radius=0.2, nsample=32, in_channel=3, mlp=[64, 64, 128], group_all=False)\n",
        "        self.sa2 = PointNet2SetAbstraction(npoint=128, radius=0.4, nsample=64, in_channel=128, mlp=[128, 128, 256], group_all=False)\n",
        "\n",
        "        self.pt_layer = PointTransformerLayer(channels=256)\n",
        "\n",
        "        self.fc_global = nn.Sequential(\n",
        "            nn.Linear(256, feature_dim),\n",
        "            nn.ReLU(), # Added activation\n",
        "            nn.Linear(feature_dim, feature_dim)\n",
        "        )\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "    def forward(self, x_xyz):\n",
        "        l1_xyz, l1_points = self.sa1(x_xyz, None) # sa1 creates features from xyz\n",
        "\n",
        "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
        "\n",
        "        if l2_points is None:\n",
        "             print(\"Error: l2_points are None after sa2. Using zeros.\")\n",
        "             l2_points = torch.zeros(l2_xyz.size(0), l2_xyz.size(1), 256, device=l2_xyz.device)\n",
        "\n",
        "        l3_features = self.pt_layer(l2_points)\n",
        "        global_feature, _ = torch.max(l3_features, dim=1)\n",
        "        final_global_feature = self.fc_global(global_feature)\n",
        "\n",
        "        return final_global_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5fBooRgxU3u"
      },
      "outputs": [],
      "source": [
        "# Loss Function\n",
        "\n",
        "def chamfer_distance(p1, p2, reduction='mean'):\n",
        "    \"\"\"Improved Chamfer Distance with NaN/Inf checks and reduction options.\"\"\"\n",
        "    p1 = p1.float() # Ensure float type\n",
        "    p2 = p2.float()\n",
        "\n",
        "    p1_expand = p1.unsqueeze(2) # (B, N, 1, 3)\n",
        "    p2_expand = p2.unsqueeze(1) # (B, 1, M, 3)\n",
        "\n",
        "    # Calculate pairwise squared distances\n",
        "    dist_matrix = torch.sum((p1_expand - p2_expand) ** 2, dim=-1) # (B, N, M)\n",
        "\n",
        "    # Handle potential numerical issues before min\n",
        "    if torch.isnan(dist_matrix).any() or torch.isinf(dist_matrix).any():\n",
        "        print(\"Warning: NaN/Inf detected in Chamfer distance matrix. Replacing with large value.\")\n",
        "        dist_matrix = torch.nan_to_num(dist_matrix, nan=1e6, posinf=1e6, neginf=1e6) # Or 0? Depends.\n",
        "\n",
        "    dist_p1_p2, _ = torch.min(dist_matrix, dim=2) # (B, N)\n",
        "    dist_p2_p1, _ = torch.min(dist_matrix, dim=1) # (B, M)\n",
        "\n",
        "    # Apply sqrt to get Euclidean distance\n",
        "    dist_p1_p2 = torch.sqrt(dist_p1_p2 + 1e-8) # Add epsilon for stability\n",
        "    dist_p2_p1 = torch.sqrt(dist_p2_p1 + 1e-8)\n",
        "\n",
        "    if reduction == 'mean':\n",
        "        loss = (torch.mean(dist_p1_p2) + torch.mean(dist_p2_p1)) / 2.0 # Often averaged\n",
        "    elif reduction == 'sum':\n",
        "        loss = torch.sum(dist_p1_p2) + torch.sum(dist_p2_p1)\n",
        "    else: # 'none'\n",
        "        loss = (dist_p1_p2, dist_p2_p1) # Return per-point distances if needed\n",
        "\n",
        "    # Final safety check\n",
        "    if torch.isnan(loss) or torch.isinf(loss):\n",
        "       print(\"Warning: Final Chamfer distance resulted in NaN/Inf. Returning 0.\")\n",
        "       return torch.tensor(0.0, device=p1.device, dtype=p1.dtype)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# class GeometricLoss(nn.Module):\n",
        "#     \"\"\"Geometric Consistency Loss - Disabled Placeholder.\"\"\"\n",
        "#     def __init__(self, weight_normal=0.7, weight_density=0.3):\n",
        "#         super().__init__()\n",
        "#         # print(\"Info: GeometricLoss is disabled (returns 0).\") # Reduce noise\n",
        "\n",
        "#     def forward(self, pred_points, target_points):\n",
        "#         return torch.tensor(0.0, device=pred_points.device)\n",
        "\n",
        "class HybridLoss(nn.Module):\n",
        "    \"\"\"Combines Prediction (SmoothL1) and Completion (Chamfer/EMD) losses.\"\"\"\n",
        "    def __init__(self, lambda_comp=0.1, comp_loss_type='chamfer'): # geom disabled\n",
        "        super().__init__()\n",
        "        self.lambda_comp = lambda_comp\n",
        "        # self.lambda_geom = lambda_geom # Will be multiplied by 0 from GeometricLoss\n",
        "        self.prediction_loss = nn.SmoothL1Loss() # Use SmoothL1Loss\n",
        "\n",
        "        if comp_loss_type == 'emd':\n",
        "            self.completion_loss = EarthMoverDistance() # Placeholder uses Chamfer\n",
        "        elif comp_loss_type == 'chamfer':\n",
        "            self.completion_loss = chamfer_distance\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported completion loss type\")\n",
        "        # self.geometric_loss = GeometricLoss() # Returns 0\n",
        "\n",
        "    def forward(self, pred_biomass, target_biomass, completed_cloud, target_cloud):\n",
        "        pred_loss = self.prediction_loss(pred_biomass, target_biomass)\n",
        "        comp_loss = self.completion_loss(completed_cloud, target_cloud)\n",
        "        # geom_loss = self.geometric_loss(completed_cloud, target_cloud) # is 0\n",
        "\n",
        "        if torch.isnan(pred_loss): pred_loss = torch.tensor(0.0, device=pred_biomass.device)\n",
        "        if torch.isnan(comp_loss): comp_loss = torch.tensor(0.0, device=completed_cloud.device)\n",
        "\n",
        "        total_loss = pred_loss + self.lambda_comp * comp_loss\n",
        "        return total_loss, pred_loss, comp_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFnOXKPZxYHW"
      },
      "outputs": [],
      "source": [
        "class BioNetEnhanced(nn.Module):\n",
        "    # __init__ remains the same\n",
        "    def __init__(self, feature_dim=1024, num_out_points=2048, use_dual_attention_vc=True, use_checkpointing=False):\n",
        "        super().__init__()\n",
        "        self.feature_dim = feature_dim\n",
        "        self.use_checkpointing = use_checkpointing\n",
        "        self.encoder = MultiScaleCompletionEncoder(feature_dim=feature_dim)\n",
        "        self.decoder = CompletionDecoder(feature_dim=feature_dim, num_out_points=num_out_points)\n",
        "        self.vc_extractor = PointFeatureExtractor(input_dim=3, feature_dim=feature_dim, use_dual_attention=use_dual_attention_vc)\n",
        "        self.projection = ProjectionModule(feature_dim=feature_dim)\n",
        "        fusion_input_dim = feature_dim * 3\n",
        "        self.fusion_mlp = nn.Sequential(\n",
        "            nn.Linear(fusion_input_dim, feature_dim), nn.ReLU(),\n",
        "            nn.Linear(feature_dim, 512))\n",
        "        self.fc_final = nn.Sequential(\n",
        "            nn.Linear(512, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 1))\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "         global_feature = self.encoder(x)\n",
        "         completed_cloud = self.decoder(global_feature)\n",
        "         vc = self.vc_extractor(completed_cloud)\n",
        "         vp = self.projection(completed_cloud)\n",
        "         fused_features = torch.cat([global_feature, vc, vp], dim=1)\n",
        "         fused_output = self.fusion_mlp(fused_features)\n",
        "         out = self.fc_final(fused_output)\n",
        "         if torch.isnan(out).any():\n",
        "              print(\"Warning: NaN detected in model output.\")\n",
        "              # Replace NaN with 0 before returning\n",
        "              out = torch.nan_to_num(out, nan=0.0)\n",
        "         return out.squeeze(1), completed_cloud\n",
        "\n",
        "    def forward(self, x):\n",
        "         if self.use_checkpointing and self.training:\n",
        "              # Ensure checkpoint inputs don't require grad if they shouldn't\n",
        "              # return checkpoint(self._forward_impl, x, use_reentrant=False) # PyTorch default changed to True, False might be needed\n",
        "              return checkpoint(self._forward_impl, x, use_reentrant=True) # Try default\n",
        "         else:\n",
        "              return self._forward_impl(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUlUGZZBxdvJ"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "def train_one_epoch(model, train_loader, optimizer, device, hybrid_loss_fn, scaler=None, augment_fn=None, grad_clip_value=1.0):\n",
        "    \"\"\" Includes optional mixed precision via scaler \"\"\"\n",
        "    model.train()\n",
        "    total_loss, total_pred_loss, total_comp_loss = 0, 0, 0\n",
        "\n",
        "    for batch_idx, (point_clouds, biomass) in enumerate(train_loader):\n",
        "        point_clouds = point_clouds.to(device)\n",
        "        biomass = biomass.to(device) # Target biomass (potentially normalized)\n",
        "\n",
        "        if augment_fn:\n",
        "            point_clouds = augment_fn(point_clouds)\n",
        "\n",
        "        target_completion_cloud = point_clouds # Use input for completion loss target\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed Precision Context\n",
        "        with torch.amp.autocast(device_type='cuda', enabled=scaler is not None):\n",
        "            pred_biomass, completed_cloud = model(point_clouds)\n",
        "            if torch.isnan(pred_biomass).any():\n",
        "                print(f\"Warning: NaN prediction detected in batch {batch_idx}. Skipping batch.\")\n",
        "                pred_biomass = torch.nan_to_num(pred_biomass, nan=0.0) # Try replacing NaN before loss\n",
        "                # continue # Skip batch entirely might be safer\n",
        "\n",
        "            loss, pred_loss, comp_loss = hybrid_loss_fn(\n",
        "                pred_biomass, biomass, completed_cloud, target_completion_cloud\n",
        "            )\n",
        "\n",
        "        if torch.isnan(loss):\n",
        "             print(f\"Warning: NaN loss detected in batch {batch_idx}. Skipping backward pass.\")\n",
        "             continue\n",
        "\n",
        "        # Scaled backward pass\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            # Unscale gradients before clipping\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_value)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_value)\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_pred_loss += pred_loss.item()\n",
        "        total_comp_loss += comp_loss.item()\n",
        "        # total_geom_loss += geom_loss.item() # Will be 0\n",
        "\n",
        "    num_batches = len(train_loader)\n",
        "    if num_batches == 0: return 0,0,0,0\n",
        "    return (total_loss / num_batches, total_pred_loss / num_batches,\n",
        "            total_comp_loss / num_batches)\n",
        "\n",
        "def evaluate(model, test_loader, device, target_scaler=None):\n",
        "    \"\"\" Added target_scaler for denormalization \"\"\"\n",
        "    model.eval()\n",
        "    preds_denorm, trues_denorm = [], []\n",
        "    with torch.no_grad():\n",
        "        for point_clouds, biomass_norm in test_loader: # Assume biomass is normalized\n",
        "            point_clouds = point_clouds.to(device)\n",
        "            biomass_norm = biomass_norm.to(device)\n",
        "\n",
        "            # Use autocast for consistency if model uses mixed precision parts\n",
        "            with torch.amp.autocast(device_type='cuda', enabled=torch.is_autocast_enabled()):\n",
        "                 pred_biomass_norm, _ = model(point_clouds)\n",
        "\n",
        "            # Handle potential NaNs in predictions\n",
        "            pred_biomass_norm = torch.nan_to_num(pred_biomass_norm, nan=0.0)\n",
        "\n",
        "            # Denormalize predictions and targets\n",
        "            if target_scaler:\n",
        "                 pred_biomass_denorm = target_scaler.inverse_transform(pred_biomass_norm.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "                 biomass_denorm = target_scaler.inverse_transform(biomass_norm.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "            else:\n",
        "                 # Assume no normalization if scaler is None\n",
        "                 pred_biomass_denorm = pred_biomass_norm.cpu().numpy()\n",
        "                 biomass_denorm = biomass_norm.cpu().numpy()\n",
        "\n",
        "            # Check for NaNs/Infs *after* denormalization (though unlikely if handled before)\n",
        "            if np.isnan(biomass_denorm).any():\n",
        "                 print(\"Warning: NaN ground truth detected during evaluation after denorm. Skipping batch.\")\n",
        "                 continue\n",
        "\n",
        "            preds_denorm.extend(pred_biomass_denorm)\n",
        "            trues_denorm.extend(biomass_denorm)\n",
        "\n",
        "    if not preds_denorm or not trues_denorm:\n",
        "         print(\"Error: No valid predictions/targets found for evaluation.\")\n",
        "         return np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "    preds = np.array(preds_denorm)\n",
        "    trues = np.array(trues_denorm)\n",
        "\n",
        "    if not np.all(np.isfinite(preds)):\n",
        "        print(f\"Error: Non-finite values found in aggregated denormalized predictions. Replacing with 0.\")\n",
        "        preds = np.nan_to_num(preds, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    if not np.all(np.isfinite(trues)):\n",
        "        print(f\"Error: Non-finite values found in aggregated denormalized ground truth.\")\n",
        "        return np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "    try:\n",
        "        mse = mean_squared_error(trues, preds)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(trues, preds)\n",
        "        if np.var(trues) < 1e-6:\n",
        "             r2 = 0.0 if mse < 1e-6 else -np.inf\n",
        "        else:\n",
        "             r2 = r2_score(trues, preds)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error calculating metrics: {e}\")\n",
        "        mse, rmse, mae, r2 = np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "    return mse, rmse, mae, r2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6t0rLMLwFMaR",
        "outputId": "1efa9386-35ab-456d-97e1-b62b3f6e97c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dr_ISv9KtUjE",
        "outputId": "f70fab64-cc0a-43d2-8b4d-ec7d1044f56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting main training function...\n",
            "Using device: cuda\n",
            "Using Automatic Mixed Precision (AMP).\n",
            "Starting training...\n",
            "Epoch [001/500] | LR: 0.001000 | Loss: 616.9676 (Pred: 608.7490, Comp: 27.3953 | Val RMSE: 577.0435 | Val MAE: 436.2925 | Val R2: -1.2373\n",
            "** Saved Best Model (Epoch 1) - RMSE: 577.0435 **\n",
            "Epoch [002/500] | LR: 0.001000 | Loss: 504.6135 (Pred: 496.6358, Comp: 26.5925 | Val RMSE: 729.9043 | Val MAE: 615.1318 | Val R2: -2.5796\n",
            "Epoch [003/500] | LR: 0.001000 | Loss: 512.5191 (Pred: 504.3312, Comp: 27.2931 | Val RMSE: 211.0206 | Val MAE: 182.1357 | Val R2: 0.7008\n",
            "** Saved Best Model (Epoch 3) - RMSE: 211.0206 **\n",
            "Epoch [004/500] | LR: 0.001000 | Loss: 169.4592 (Pred: 161.1921, Comp: 27.5570 | Val RMSE: 149.5124 | Val MAE: 116.9186 | Val R2: 0.8498\n",
            "** Saved Best Model (Epoch 4) - RMSE: 149.5124 **\n",
            "Epoch [005/500] | LR: 0.001000 | Loss: 145.9485 (Pred: 137.6993, Comp: 27.4975 | Val RMSE: 156.4221 | Val MAE: 126.4541 | Val R2: 0.8356\n",
            "Epoch [006/500] | LR: 0.001000 | Loss: 135.6963 (Pred: 127.5280, Comp: 27.2277 | Val RMSE: 137.2450 | Val MAE: 108.8306 | Val R2: 0.8734\n",
            "** Saved Best Model (Epoch 6) - RMSE: 137.2450 **\n",
            "Epoch [007/500] | LR: 0.001000 | Loss: 119.2951 (Pred: 111.1343, Comp: 27.2026 | Val RMSE: 159.3201 | Val MAE: 128.5588 | Val R2: 0.8295\n",
            "Epoch [008/500] | LR: 0.001000 | Loss: 117.0914 (Pred: 108.9673, Comp: 27.0804 | Val RMSE: 185.3143 | Val MAE: 140.6745 | Val R2: 0.7693\n",
            "Epoch [009/500] | LR: 0.000999 | Loss: 131.7807 (Pred: 123.6255, Comp: 27.1839 | Val RMSE: 181.0011 | Val MAE: 142.4599 | Val R2: 0.7799\n",
            "Epoch [010/500] | LR: 0.000999 | Loss: 118.0331 (Pred: 109.8148, Comp: 27.3942 | Val RMSE: 149.1970 | Val MAE: 107.1967 | Val R2: 0.8504\n",
            "Epoch [011/500] | LR: 0.000999 | Loss: 102.4133 (Pred: 94.1324, Comp: 27.6030 | Val RMSE: 127.9641 | Val MAE: 99.7295 | Val R2: 0.8900\n",
            "** Saved Best Model (Epoch 11) - RMSE: 127.9641 **\n",
            "Epoch [012/500] | LR: 0.000999 | Loss: 136.0340 (Pred: 127.8233, Comp: 27.3690 | Val RMSE: 168.3881 | Val MAE: 132.3755 | Val R2: 0.8095\n",
            "Epoch [013/500] | LR: 0.000999 | Loss: 105.8262 (Pred: 97.6324, Comp: 27.3126 | Val RMSE: 152.6074 | Val MAE: 116.6521 | Val R2: 0.8435\n",
            "Epoch [014/500] | LR: 0.000998 | Loss: 93.9621 (Pred: 85.7596, Comp: 27.3416 | Val RMSE: 135.7125 | Val MAE: 103.6664 | Val R2: 0.8763\n",
            "Epoch [015/500] | LR: 0.000998 | Loss: 101.6653 (Pred: 93.4770, Comp: 27.2942 | Val RMSE: 131.5599 | Val MAE: 104.4930 | Val R2: 0.8837\n",
            "Epoch [016/500] | LR: 0.000998 | Loss: 99.0069 (Pred: 90.8911, Comp: 27.0527 | Val RMSE: 126.0290 | Val MAE: 96.3494 | Val R2: 0.8933\n",
            "** Saved Best Model (Epoch 16) - RMSE: 126.0290 **\n",
            "Epoch [017/500] | LR: 0.000998 | Loss: 100.3010 (Pred: 92.1829, Comp: 27.0603 | Val RMSE: 156.1313 | Val MAE: 127.1023 | Val R2: 0.8362\n",
            "Epoch [018/500] | LR: 0.000997 | Loss: 100.8829 (Pred: 92.7768, Comp: 27.0203 | Val RMSE: 172.2687 | Val MAE: 133.8430 | Val R2: 0.8006\n",
            "Epoch [019/500] | LR: 0.000997 | Loss: 143.5428 (Pred: 135.4664, Comp: 26.9212 | Val RMSE: 117.2361 | Val MAE: 94.2092 | Val R2: 0.9077\n",
            "** Saved Best Model (Epoch 19) - RMSE: 117.2361 **\n",
            "Epoch [020/500] | LR: 0.000997 | Loss: 111.8828 (Pred: 103.7196, Comp: 27.2106 | Val RMSE: 166.5227 | Val MAE: 127.4198 | Val R2: 0.8137\n",
            "Epoch [021/500] | LR: 0.000996 | Loss: 98.0755 (Pred: 89.8816, Comp: 27.3130 | Val RMSE: 130.2137 | Val MAE: 97.7289 | Val R2: 0.8861\n",
            "Epoch [022/500] | LR: 0.000996 | Loss: 108.9953 (Pred: 100.8189, Comp: 27.2547 | Val RMSE: 115.2159 | Val MAE: 90.5223 | Val R2: 0.9108\n",
            "** Saved Best Model (Epoch 22) - RMSE: 115.2159 **\n",
            "Epoch [023/500] | LR: 0.000996 | Loss: 91.1767 (Pred: 83.0175, Comp: 27.1973 | Val RMSE: 126.3324 | Val MAE: 98.0200 | Val R2: 0.8928\n",
            "Epoch [024/500] | LR: 0.000995 | Loss: 95.3514 (Pred: 87.2839, Comp: 26.8917 | Val RMSE: 126.8188 | Val MAE: 98.6539 | Val R2: 0.8919\n",
            "Epoch [025/500] | LR: 0.000995 | Loss: 103.2053 (Pred: 95.1044, Comp: 27.0030 | Val RMSE: 125.5002 | Val MAE: 101.9675 | Val R2: 0.8942\n",
            "Epoch [026/500] | LR: 0.000994 | Loss: 100.1295 (Pred: 92.0843, Comp: 26.8176 | Val RMSE: 107.3274 | Val MAE: 90.5931 | Val R2: 0.9226\n",
            "** Saved Best Model (Epoch 26) - RMSE: 107.3274 **\n",
            "Epoch [027/500] | LR: 0.000994 | Loss: 97.7168 (Pred: 89.5630, Comp: 27.1793 | Val RMSE: 131.3187 | Val MAE: 101.3560 | Val R2: 0.8841\n",
            "Epoch [028/500] | LR: 0.000994 | Loss: 101.0729 (Pred: 92.9839, Comp: 26.9635 | Val RMSE: 129.7049 | Val MAE: 97.9346 | Val R2: 0.8870\n",
            "Epoch [029/500] | LR: 0.000993 | Loss: 97.0653 (Pred: 89.0183, Comp: 26.8234 | Val RMSE: 138.1708 | Val MAE: 109.6289 | Val R2: 0.8717\n",
            "Epoch [030/500] | LR: 0.000993 | Loss: 102.0977 (Pred: 94.0438, Comp: 26.8466 | Val RMSE: 111.1423 | Val MAE: 90.4725 | Val R2: 0.9170\n",
            "Epoch [031/500] | LR: 0.000992 | Loss: 91.3499 (Pred: 83.3267, Comp: 26.7438 | Val RMSE: 131.2182 | Val MAE: 100.2365 | Val R2: 0.8843\n",
            "Epoch [032/500] | LR: 0.000991 | Loss: 92.2207 (Pred: 84.2131, Comp: 26.6919 | Val RMSE: 145.6728 | Val MAE: 113.6126 | Val R2: 0.8574\n",
            "Epoch [033/500] | LR: 0.000991 | Loss: 101.2437 (Pred: 93.2341, Comp: 26.6988 | Val RMSE: 136.3007 | Val MAE: 116.1192 | Val R2: 0.8752\n",
            "Epoch [034/500] | LR: 0.000990 | Loss: 93.7655 (Pred: 85.7761, Comp: 26.6315 | Val RMSE: 127.5997 | Val MAE: 95.0887 | Val R2: 0.8906\n",
            "Epoch [035/500] | LR: 0.000990 | Loss: 87.6163 (Pred: 79.5745, Comp: 26.8061 | Val RMSE: 146.0824 | Val MAE: 113.2721 | Val R2: 0.8566\n",
            "Epoch [036/500] | LR: 0.000989 | Loss: 84.1805 (Pred: 76.1867, Comp: 26.6461 | Val RMSE: 121.2928 | Val MAE: 95.0967 | Val R2: 0.9012\n",
            "Epoch [037/500] | LR: 0.000989 | Loss: 84.7554 (Pred: 76.8403, Comp: 26.3837 | Val RMSE: 109.5029 | Val MAE: 86.4937 | Val R2: 0.9194\n",
            "Epoch [038/500] | LR: 0.000988 | Loss: 88.8838 (Pred: 81.0453, Comp: 26.1285 | Val RMSE: 133.1429 | Val MAE: 100.8792 | Val R2: 0.8809\n",
            "Epoch [039/500] | LR: 0.000987 | Loss: 95.7723 (Pred: 87.9630, Comp: 26.0310 | Val RMSE: 104.2247 | Val MAE: 81.7358 | Val R2: 0.9270\n",
            "** Saved Best Model (Epoch 39) - RMSE: 104.2247 **\n",
            "Epoch [040/500] | LR: 0.000987 | Loss: 99.6897 (Pred: 91.9163, Comp: 25.9115 | Val RMSE: 111.9568 | Val MAE: 85.8199 | Val R2: 0.9158\n",
            "Epoch [041/500] | LR: 0.000986 | Loss: 88.4810 (Pred: 80.7372, Comp: 25.8128 | Val RMSE: 116.8817 | Val MAE: 88.1787 | Val R2: 0.9082\n",
            "Epoch [042/500] | LR: 0.000985 | Loss: 83.1020 (Pred: 75.3577, Comp: 25.8142 | Val RMSE: 123.8377 | Val MAE: 94.4526 | Val R2: 0.8970\n",
            "Epoch [043/500] | LR: 0.000984 | Loss: 105.7089 (Pred: 97.9902, Comp: 25.7290 | Val RMSE: 177.1626 | Val MAE: 143.2088 | Val R2: 0.7891\n",
            "Epoch [044/500] | LR: 0.000984 | Loss: 93.8529 (Pred: 86.1786, Comp: 25.5811 | Val RMSE: 119.1893 | Val MAE: 90.9711 | Val R2: 0.9046\n",
            "Epoch [045/500] | LR: 0.000983 | Loss: 89.5317 (Pred: 81.9042, Comp: 25.4249 | Val RMSE: 126.6362 | Val MAE: 94.7164 | Val R2: 0.8923\n",
            "Epoch [046/500] | LR: 0.000982 | Loss: 86.9098 (Pred: 79.3023, Comp: 25.3582 | Val RMSE: 141.8331 | Val MAE: 104.0318 | Val R2: 0.8648\n",
            "Epoch [047/500] | LR: 0.000981 | Loss: 87.8021 (Pred: 80.1011, Comp: 25.6701 | Val RMSE: 164.6426 | Val MAE: 126.8056 | Val R2: 0.8179\n",
            "Epoch [048/500] | LR: 0.000981 | Loss: 94.5056 (Pred: 86.8994, Comp: 25.3542 | Val RMSE: 109.2084 | Val MAE: 86.0153 | Val R2: 0.9199\n",
            "Epoch [049/500] | LR: 0.000980 | Loss: 102.5057 (Pred: 94.8614, Comp: 25.4810 | Val RMSE: 133.9760 | Val MAE: 102.0728 | Val R2: 0.8794\n",
            "Epoch [050/500] | LR: 0.000979 | Loss: 82.2278 (Pred: 74.5464, Comp: 25.6049 | Val RMSE: 112.0095 | Val MAE: 85.4281 | Val R2: 0.9157\n",
            "Epoch [051/500] | LR: 0.000978 | Loss: 85.1005 (Pred: 77.4834, Comp: 25.3904 | Val RMSE: 105.9554 | Val MAE: 80.6779 | Val R2: 0.9246\n",
            "Epoch [052/500] | LR: 0.000977 | Loss: 93.2504 (Pred: 85.6696, Comp: 25.2694 | Val RMSE: 121.2308 | Val MAE: 91.9227 | Val R2: 0.9013\n",
            "Epoch [053/500] | LR: 0.000976 | Loss: 114.1114 (Pred: 106.4999, Comp: 25.3716 | Val RMSE: 214.1735 | Val MAE: 163.3674 | Val R2: 0.6918\n",
            "Epoch [054/500] | LR: 0.000975 | Loss: 121.0847 (Pred: 113.5056, Comp: 25.2635 | Val RMSE: 199.8387 | Val MAE: 165.2252 | Val R2: 0.7317\n",
            "Epoch [055/500] | LR: 0.000974 | Loss: 117.0464 (Pred: 109.5031, Comp: 25.1442 | Val RMSE: 127.0264 | Val MAE: 93.0907 | Val R2: 0.8916\n",
            "Epoch [056/500] | LR: 0.000973 | Loss: 92.6076 (Pred: 85.0991, Comp: 25.0283 | Val RMSE: 107.3374 | Val MAE: 84.4298 | Val R2: 0.9226\n",
            "Epoch [057/500] | LR: 0.000972 | Loss: 84.3479 (Pred: 76.8594, Comp: 24.9616 | Val RMSE: 112.2468 | Val MAE: 86.1271 | Val R2: 0.9153\n",
            "Epoch [058/500] | LR: 0.000971 | Loss: 88.1024 (Pred: 80.5526, Comp: 25.1660 | Val RMSE: 106.3414 | Val MAE: 84.4703 | Val R2: 0.9240\n",
            "Epoch [059/500] | LR: 0.000970 | Loss: 90.7870 (Pred: 83.2482, Comp: 25.1294 | Val RMSE: 105.3279 | Val MAE: 82.1171 | Val R2: 0.9255\n",
            "Epoch [060/500] | LR: 0.000969 | Loss: 87.1757 (Pred: 79.6423, Comp: 25.1113 | Val RMSE: 125.6061 | Val MAE: 90.2427 | Val R2: 0.8940\n",
            "Epoch [061/500] | LR: 0.000968 | Loss: 88.5013 (Pred: 80.8923, Comp: 25.3634 | Val RMSE: 107.1159 | Val MAE: 84.3202 | Val R2: 0.9229\n",
            "Epoch [062/500] | LR: 0.000967 | Loss: 85.3664 (Pred: 77.8765, Comp: 24.9662 | Val RMSE: 163.9721 | Val MAE: 127.4213 | Val R2: 0.8193\n",
            "Epoch [063/500] | LR: 0.000966 | Loss: 99.5592 (Pred: 92.0463, Comp: 25.0429 | Val RMSE: 137.6877 | Val MAE: 108.1844 | Val R2: 0.8726\n",
            "Epoch [064/500] | LR: 0.000965 | Loss: 87.6681 (Pred: 80.1830, Comp: 24.9504 | Val RMSE: 186.9399 | Val MAE: 144.8658 | Val R2: 0.7652\n",
            "Epoch [065/500] | LR: 0.000964 | Loss: 99.9402 (Pred: 92.4517, Comp: 24.9617 | Val RMSE: 192.3930 | Val MAE: 142.5363 | Val R2: 0.7513\n",
            "Epoch [066/500] | LR: 0.000963 | Loss: 97.1815 (Pred: 89.6495, Comp: 25.1066 | Val RMSE: 145.5907 | Val MAE: 111.2263 | Val R2: 0.8576\n",
            "Epoch [067/500] | LR: 0.000962 | Loss: 96.2595 (Pred: 88.7084, Comp: 25.1705 | Val RMSE: 113.2294 | Val MAE: 88.7540 | Val R2: 0.9139\n",
            "Epoch [068/500] | LR: 0.000961 | Loss: 87.6486 (Pred: 80.1392, Comp: 25.0313 | Val RMSE: 108.7925 | Val MAE: 84.3207 | Val R2: 0.9205\n",
            "Epoch [069/500] | LR: 0.000960 | Loss: 81.0274 (Pred: 73.5569, Comp: 24.9017 | Val RMSE: 102.6621 | Val MAE: 77.9334 | Val R2: 0.9292\n",
            "** Saved Best Model (Epoch 69) - RMSE: 102.6621 **\n",
            "Epoch [070/500] | LR: 0.000958 | Loss: 87.3954 (Pred: 79.8448, Comp: 25.1688 | Val RMSE: 187.8414 | Val MAE: 148.9388 | Val R2: 0.7629\n",
            "Epoch [071/500] | LR: 0.000957 | Loss: 94.6918 (Pred: 87.1099, Comp: 25.2730 | Val RMSE: 105.8920 | Val MAE: 81.7413 | Val R2: 0.9247\n",
            "Epoch [072/500] | LR: 0.000956 | Loss: 89.5116 (Pred: 81.9737, Comp: 25.1264 | Val RMSE: 138.3904 | Val MAE: 109.7119 | Val R2: 0.8713\n",
            "Epoch [073/500] | LR: 0.000955 | Loss: 85.0443 (Pred: 77.4740, Comp: 25.2343 | Val RMSE: 175.3525 | Val MAE: 126.8851 | Val R2: 0.7934\n",
            "Epoch [074/500] | LR: 0.000953 | Loss: 87.2856 (Pred: 79.7305, Comp: 25.1835 | Val RMSE: 120.9389 | Val MAE: 90.7332 | Val R2: 0.9017\n",
            "Epoch [075/500] | LR: 0.000952 | Loss: 80.1494 (Pred: 72.5175, Comp: 25.4397 | Val RMSE: 102.6309 | Val MAE: 79.1910 | Val R2: 0.9292\n",
            "** Saved Best Model (Epoch 75) - RMSE: 102.6309 **\n",
            "Epoch [076/500] | LR: 0.000951 | Loss: 81.8856 (Pred: 74.2789, Comp: 25.3555 | Val RMSE: 117.1375 | Val MAE: 89.1592 | Val R2: 0.9078\n",
            "Epoch [077/500] | LR: 0.000950 | Loss: 88.8246 (Pred: 81.2054, Comp: 25.3972 | Val RMSE: 109.1592 | Val MAE: 84.5247 | Val R2: 0.9199\n",
            "Epoch [078/500] | LR: 0.000948 | Loss: 83.6316 (Pred: 76.0956, Comp: 25.1202 | Val RMSE: 143.1348 | Val MAE: 111.3711 | Val R2: 0.8623\n",
            "Epoch [079/500] | LR: 0.000947 | Loss: 93.6703 (Pred: 86.1451, Comp: 25.0841 | Val RMSE: 121.4437 | Val MAE: 95.8415 | Val R2: 0.9009\n",
            "Epoch [080/500] | LR: 0.000946 | Loss: 98.7828 (Pred: 91.3405, Comp: 24.8078 | Val RMSE: 235.1635 | Val MAE: 196.2897 | Val R2: 0.6284\n",
            "Epoch [081/500] | LR: 0.000944 | Loss: 155.4379 (Pred: 147.9419, Comp: 24.9865 | Val RMSE: 183.5569 | Val MAE: 140.0617 | Val R2: 0.7736\n",
            "Epoch [082/500] | LR: 0.000943 | Loss: 89.5446 (Pred: 82.0284, Comp: 25.0538 | Val RMSE: 101.2856 | Val MAE: 77.5875 | Val R2: 0.9311\n",
            "** Saved Best Model (Epoch 82) - RMSE: 101.2856 **\n",
            "Epoch [083/500] | LR: 0.000942 | Loss: 79.2796 (Pred: 71.8223, Comp: 24.8577 | Val RMSE: 100.0422 | Val MAE: 75.2021 | Val R2: 0.9328\n",
            "** Saved Best Model (Epoch 83) - RMSE: 100.0422 **\n",
            "Epoch [084/500] | LR: 0.000940 | Loss: 73.6172 (Pred: 66.0754, Comp: 25.1393 | Val RMSE: 166.5416 | Val MAE: 129.0646 | Val R2: 0.8136\n",
            "Epoch [085/500] | LR: 0.000939 | Loss: 84.5765 (Pred: 76.9678, Comp: 25.3620 | Val RMSE: 104.2465 | Val MAE: 81.1728 | Val R2: 0.9270\n",
            "Epoch [086/500] | LR: 0.000937 | Loss: 82.1374 (Pred: 74.5110, Comp: 25.4212 | Val RMSE: 143.3921 | Val MAE: 103.6046 | Val R2: 0.8619\n",
            "Epoch [087/500] | LR: 0.000936 | Loss: 74.5076 (Pred: 66.8757, Comp: 25.4395 | Val RMSE: 106.9103 | Val MAE: 79.8038 | Val R2: 0.9232\n",
            "Epoch [088/500] | LR: 0.000934 | Loss: 82.4574 (Pred: 74.6939, Comp: 25.8785 | Val RMSE: 123.4572 | Val MAE: 91.9181 | Val R2: 0.8976\n",
            "Epoch [089/500] | LR: 0.000933 | Loss: 79.4216 (Pred: 71.8052, Comp: 25.3883 | Val RMSE: 147.3895 | Val MAE: 104.4010 | Val R2: 0.8540\n",
            "Epoch [090/500] | LR: 0.000931 | Loss: 95.2329 (Pred: 87.6516, Comp: 25.2709 | Val RMSE: 218.3462 | Val MAE: 168.5021 | Val R2: 0.6797\n",
            "Epoch [091/500] | LR: 0.000930 | Loss: 128.3031 (Pred: 120.6640, Comp: 25.4638 | Val RMSE: 190.4154 | Val MAE: 145.5529 | Val R2: 0.7564\n",
            "Epoch [092/500] | LR: 0.000928 | Loss: 106.5809 (Pred: 98.9721, Comp: 25.3624 | Val RMSE: 259.1094 | Val MAE: 208.1795 | Val R2: 0.5489\n",
            "Epoch [093/500] | LR: 0.000927 | Loss: 148.4148 (Pred: 140.8327, Comp: 25.2737 | Val RMSE: 218.5161 | Val MAE: 161.6506 | Val R2: 0.6792\n",
            "Epoch [094/500] | LR: 0.000925 | Loss: 87.6071 (Pred: 79.9876, Comp: 25.3982 | Val RMSE: 103.0710 | Val MAE: 79.4299 | Val R2: 0.9286\n",
            "Epoch [095/500] | LR: 0.000924 | Loss: 73.2746 (Pred: 65.6538, Comp: 25.4029 | Val RMSE: 105.8929 | Val MAE: 75.4987 | Val R2: 0.9247\n",
            "Epoch [096/500] | LR: 0.000922 | Loss: 73.5294 (Pred: 65.9135, Comp: 25.3862 | Val RMSE: 178.5021 | Val MAE: 129.9416 | Val R2: 0.7859\n",
            "Epoch [097/500] | LR: 0.000921 | Loss: 82.5609 (Pred: 74.9734, Comp: 25.2917 | Val RMSE: 137.6769 | Val MAE: 98.2584 | Val R2: 0.8726\n",
            "Epoch [098/500] | LR: 0.000919 | Loss: 83.0577 (Pred: 75.4703, Comp: 25.2912 | Val RMSE: 102.1242 | Val MAE: 74.6422 | Val R2: 0.9299\n",
            "Epoch [099/500] | LR: 0.000917 | Loss: 77.2261 (Pred: 69.6379, Comp: 25.2941 | Val RMSE: 120.9104 | Val MAE: 92.6236 | Val R2: 0.9018\n",
            "Epoch [100/500] | LR: 0.000916 | Loss: 83.8262 (Pred: 76.2524, Comp: 25.2458 | Val RMSE: 97.8429 | Val MAE: 73.8653 | Val R2: 0.9357\n",
            "** Saved Best Model (Epoch 100) - RMSE: 97.8429 **\n",
            "Epoch [101/500] | LR: 0.000914 | Loss: 77.4719 (Pred: 69.9545, Comp: 25.0580 | Val RMSE: 98.5652 | Val MAE: 74.3564 | Val R2: 0.9347\n",
            "Epoch [102/500] | LR: 0.000912 | Loss: 83.3339 (Pred: 75.8167, Comp: 25.0572 | Val RMSE: 97.4106 | Val MAE: 75.4864 | Val R2: 0.9362\n",
            "** Saved Best Model (Epoch 102) - RMSE: 97.4106 **\n",
            "Epoch [103/500] | LR: 0.000911 | Loss: 77.9522 (Pred: 70.4878, Comp: 24.8812 | Val RMSE: 109.6311 | Val MAE: 83.5455 | Val R2: 0.9192\n",
            "Epoch [104/500] | LR: 0.000909 | Loss: 82.4176 (Pred: 74.9290, Comp: 24.9620 | Val RMSE: 114.9191 | Val MAE: 86.7430 | Val R2: 0.9113\n",
            "Epoch [105/500] | LR: 0.000907 | Loss: 81.2767 (Pred: 73.7619, Comp: 25.0494 | Val RMSE: 132.5098 | Val MAE: 98.1707 | Val R2: 0.8820\n",
            "Epoch [106/500] | LR: 0.000906 | Loss: 82.6985 (Pred: 75.2786, Comp: 24.7329 | Val RMSE: 168.0736 | Val MAE: 124.5707 | Val R2: 0.8102\n",
            "Epoch [107/500] | LR: 0.000904 | Loss: 82.8780 (Pred: 75.4829, Comp: 24.6503 | Val RMSE: 112.0898 | Val MAE: 81.8125 | Val R2: 0.9156\n",
            "Epoch [108/500] | LR: 0.000902 | Loss: 78.9803 (Pred: 71.6029, Comp: 24.5915 | Val RMSE: 109.2734 | Val MAE: 82.8620 | Val R2: 0.9198\n",
            "Epoch [109/500] | LR: 0.000900 | Loss: 84.8490 (Pred: 77.4373, Comp: 24.7058 | Val RMSE: 92.8549 | Val MAE: 71.7251 | Val R2: 0.9421\n",
            "** Saved Best Model (Epoch 109) - RMSE: 92.8549 **\n",
            "Epoch [110/500] | LR: 0.000899 | Loss: 69.5468 (Pred: 62.2719, Comp: 24.2497 | Val RMSE: 97.2493 | Val MAE: 76.4946 | Val R2: 0.9365\n",
            "Epoch [111/500] | LR: 0.000897 | Loss: 91.4048 (Pred: 84.0822, Comp: 24.4089 | Val RMSE: 108.6001 | Val MAE: 79.6598 | Val R2: 0.9208\n",
            "Epoch [112/500] | LR: 0.000895 | Loss: 74.9616 (Pred: 67.6381, Comp: 24.4119 | Val RMSE: 113.5017 | Val MAE: 83.7942 | Val R2: 0.9134\n",
            "Epoch [113/500] | LR: 0.000893 | Loss: 75.0370 (Pred: 67.7041, Comp: 24.4430 | Val RMSE: 116.6072 | Val MAE: 82.2991 | Val R2: 0.9086\n",
            "Epoch [114/500] | LR: 0.000891 | Loss: 69.9923 (Pred: 62.6926, Comp: 24.3323 | Val RMSE: 114.7268 | Val MAE: 84.0261 | Val R2: 0.9116\n",
            "Epoch [115/500] | LR: 0.000889 | Loss: 76.3560 (Pred: 69.1083, Comp: 24.1588 | Val RMSE: 99.6219 | Val MAE: 75.1611 | Val R2: 0.9333\n",
            "Epoch [116/500] | LR: 0.000888 | Loss: 76.3258 (Pred: 69.0934, Comp: 24.1079 | Val RMSE: 98.2194 | Val MAE: 70.6151 | Val R2: 0.9352\n",
            "Epoch [117/500] | LR: 0.000886 | Loss: 74.2914 (Pred: 67.0392, Comp: 24.1740 | Val RMSE: 163.9984 | Val MAE: 125.5676 | Val R2: 0.8193\n",
            "Epoch [118/500] | LR: 0.000884 | Loss: 93.8664 (Pred: 86.7191, Comp: 23.8245 | Val RMSE: 196.9427 | Val MAE: 147.8216 | Val R2: 0.7394\n",
            "Epoch [119/500] | LR: 0.000882 | Loss: 76.9957 (Pred: 69.8402, Comp: 23.8518 | Val RMSE: 109.1943 | Val MAE: 78.0118 | Val R2: 0.9199\n",
            "Epoch [120/500] | LR: 0.000880 | Loss: 69.7909 (Pred: 62.6611, Comp: 23.7659 | Val RMSE: 110.1865 | Val MAE: 86.3072 | Val R2: 0.9184\n",
            "Epoch [121/500] | LR: 0.000878 | Loss: 77.7787 (Pred: 70.6004, Comp: 23.9277 | Val RMSE: 141.2938 | Val MAE: 107.3422 | Val R2: 0.8659\n",
            "Epoch [122/500] | LR: 0.000876 | Loss: 71.9933 (Pred: 64.7935, Comp: 23.9993 | Val RMSE: 108.4288 | Val MAE: 78.9069 | Val R2: 0.9210\n",
            "Epoch [123/500] | LR: 0.000874 | Loss: 78.7224 (Pred: 71.5555, Comp: 23.8896 | Val RMSE: 104.5464 | Val MAE: 80.3117 | Val R2: 0.9266\n",
            "Epoch [124/500] | LR: 0.000872 | Loss: 70.4931 (Pred: 63.3438, Comp: 23.8311 | Val RMSE: 106.1894 | Val MAE: 77.6168 | Val R2: 0.9242\n",
            "Epoch [125/500] | LR: 0.000870 | Loss: 70.7938 (Pred: 63.6711, Comp: 23.7425 | Val RMSE: 102.4358 | Val MAE: 76.0808 | Val R2: 0.9295\n",
            "Epoch [126/500] | LR: 0.000868 | Loss: 80.5763 (Pred: 73.3934, Comp: 23.9432 | Val RMSE: 102.5738 | Val MAE: 72.8360 | Val R2: 0.9293\n",
            "Epoch [127/500] | LR: 0.000866 | Loss: 68.8798 (Pred: 61.7286, Comp: 23.8372 | Val RMSE: 116.1766 | Val MAE: 84.8927 | Val R2: 0.9093\n",
            "Epoch [128/500] | LR: 0.000864 | Loss: 66.1458 (Pred: 58.9691, Comp: 23.9222 | Val RMSE: 156.1986 | Val MAE: 121.5653 | Val R2: 0.8361\n",
            "Epoch [129/500] | LR: 0.000862 | Loss: 83.6890 (Pred: 76.5176, Comp: 23.9047 | Val RMSE: 103.2869 | Val MAE: 79.6967 | Val R2: 0.9283\n",
            "Epoch [130/500] | LR: 0.000860 | Loss: 85.2934 (Pred: 78.1272, Comp: 23.8874 | Val RMSE: 95.8191 | Val MAE: 71.5592 | Val R2: 0.9383\n",
            "Epoch [131/500] | LR: 0.000858 | Loss: 67.0931 (Pred: 59.9622, Comp: 23.7694 | Val RMSE: 105.9526 | Val MAE: 79.0540 | Val R2: 0.9246\n",
            "Epoch [132/500] | LR: 0.000856 | Loss: 75.1572 (Pred: 68.0828, Comp: 23.5814 | Val RMSE: 99.4463 | Val MAE: 76.2017 | Val R2: 0.9336\n",
            "Epoch [133/500] | LR: 0.000854 | Loss: 99.6459 (Pred: 92.4686, Comp: 23.9243 | Val RMSE: 165.0070 | Val MAE: 136.8886 | Val R2: 0.8171\n",
            "Epoch [134/500] | LR: 0.000852 | Loss: 100.0806 (Pred: 92.9304, Comp: 23.8342 | Val RMSE: 182.1264 | Val MAE: 142.6791 | Val R2: 0.7771\n",
            "Epoch [135/500] | LR: 0.000850 | Loss: 118.8299 (Pred: 111.6936, Comp: 23.7877 | Val RMSE: 226.5192 | Val MAE: 185.3938 | Val R2: 0.6552\n",
            "Epoch [136/500] | LR: 0.000848 | Loss: 91.2537 (Pred: 84.1749, Comp: 23.5959 | Val RMSE: 140.3327 | Val MAE: 99.7588 | Val R2: 0.8677\n",
            "Epoch [137/500] | LR: 0.000845 | Loss: 76.6556 (Pred: 69.6110, Comp: 23.4822 | Val RMSE: 145.3063 | Val MAE: 106.8337 | Val R2: 0.8581\n",
            "Epoch [138/500] | LR: 0.000843 | Loss: 84.7927 (Pred: 77.6793, Comp: 23.7114 | Val RMSE: 117.5998 | Val MAE: 84.2974 | Val R2: 0.9071\n",
            "Epoch [139/500] | LR: 0.000841 | Loss: 76.9849 (Pred: 69.8626, Comp: 23.7409 | Val RMSE: 116.6176 | Val MAE: 82.4414 | Val R2: 0.9086\n",
            "Epoch [140/500] | LR: 0.000839 | Loss: 69.8730 (Pred: 62.7532, Comp: 23.7324 | Val RMSE: 112.4640 | Val MAE: 76.3532 | Val R2: 0.9150\n",
            "Epoch [141/500] | LR: 0.000837 | Loss: 72.6666 (Pred: 65.5156, Comp: 23.8365 | Val RMSE: 114.7390 | Val MAE: 85.0211 | Val R2: 0.9115\n",
            "Epoch [142/500] | LR: 0.000835 | Loss: 73.8375 (Pred: 66.8070, Comp: 23.4351 | Val RMSE: 127.6533 | Val MAE: 98.1856 | Val R2: 0.8905\n",
            "Epoch [143/500] | LR: 0.000832 | Loss: 75.3869 (Pred: 68.2716, Comp: 23.7174 | Val RMSE: 118.1899 | Val MAE: 80.3368 | Val R2: 0.9061\n",
            "Epoch [144/500] | LR: 0.000830 | Loss: 81.0839 (Pred: 74.0218, Comp: 23.5404 | Val RMSE: 107.4306 | Val MAE: 76.8308 | Val R2: 0.9225\n",
            "Epoch [145/500] | LR: 0.000828 | Loss: 77.9265 (Pred: 70.8538, Comp: 23.5756 | Val RMSE: 141.9387 | Val MAE: 103.3876 | Val R2: 0.8646\n",
            "Epoch [146/500] | LR: 0.000826 | Loss: 68.2974 (Pred: 61.2164, Comp: 23.6035 | Val RMSE: 126.4736 | Val MAE: 95.9142 | Val R2: 0.8925\n",
            "Epoch [147/500] | LR: 0.000824 | Loss: 80.0842 (Pred: 73.0256, Comp: 23.5289 | Val RMSE: 111.7770 | Val MAE: 84.3493 | Val R2: 0.9161\n",
            "Epoch [148/500] | LR: 0.000821 | Loss: 68.1211 (Pred: 61.0709, Comp: 23.5008 | Val RMSE: 204.7218 | Val MAE: 150.0996 | Val R2: 0.7184\n",
            "Epoch [149/500] | LR: 0.000819 | Loss: 84.8993 (Pred: 77.9780, Comp: 23.0710 | Val RMSE: 113.7120 | Val MAE: 83.2227 | Val R2: 0.9131\n",
            "Epoch [150/500] | LR: 0.000817 | Loss: 80.2730 (Pred: 73.2902, Comp: 23.2757 | Val RMSE: 130.9404 | Val MAE: 103.4063 | Val R2: 0.8848\n",
            "Epoch [151/500] | LR: 0.000815 | Loss: 76.7755 (Pred: 69.7476, Comp: 23.4264 | Val RMSE: 119.2991 | Val MAE: 83.3453 | Val R2: 0.9044\n",
            "Epoch [152/500] | LR: 0.000812 | Loss: 66.0740 (Pred: 59.0330, Comp: 23.4701 | Val RMSE: 108.3394 | Val MAE: 86.6702 | Val R2: 0.9211\n",
            "Epoch [153/500] | LR: 0.000810 | Loss: 71.4020 (Pred: 64.3765, Comp: 23.4184 | Val RMSE: 151.8310 | Val MAE: 117.3011 | Val R2: 0.8451\n",
            "Epoch [154/500] | LR: 0.000808 | Loss: 72.6430 (Pred: 65.5626, Comp: 23.6012 | Val RMSE: 144.4069 | Val MAE: 114.5072 | Val R2: 0.8599\n",
            "Epoch [155/500] | LR: 0.000805 | Loss: 82.1860 (Pred: 75.1806, Comp: 23.3514 | Val RMSE: 114.6909 | Val MAE: 86.6973 | Val R2: 0.9116\n",
            "Epoch [156/500] | LR: 0.000803 | Loss: 73.7695 (Pred: 66.7437, Comp: 23.4194 | Val RMSE: 194.8163 | Val MAE: 146.8002 | Val R2: 0.7450\n",
            "Epoch [157/500] | LR: 0.000801 | Loss: 131.5450 (Pred: 124.4755, Comp: 23.5650 | Val RMSE: 173.5799 | Val MAE: 137.4848 | Val R2: 0.7976\n",
            "Epoch [158/500] | LR: 0.000798 | Loss: 76.3677 (Pred: 69.2699, Comp: 23.6591 | Val RMSE: 124.5391 | Val MAE: 97.4309 | Val R2: 0.8958\n",
            "Epoch [159/500] | LR: 0.000796 | Loss: 71.9326 (Pred: 64.9405, Comp: 23.3069 | Val RMSE: 94.7920 | Val MAE: 69.0892 | Val R2: 0.9396\n",
            "Epoch [160/500] | LR: 0.000794 | Loss: 79.5007 (Pred: 72.4932, Comp: 23.3583 | Val RMSE: 136.1238 | Val MAE: 106.1415 | Val R2: 0.8755\n",
            "Epoch [161/500] | LR: 0.000791 | Loss: 101.7726 (Pred: 94.7703, Comp: 23.3412 | Val RMSE: 156.0621 | Val MAE: 108.9211 | Val R2: 0.8364\n",
            "Epoch [162/500] | LR: 0.000789 | Loss: 105.9059 (Pred: 98.9592, Comp: 23.1559 | Val RMSE: 130.2054 | Val MAE: 91.5354 | Val R2: 0.8861\n",
            "Epoch [163/500] | LR: 0.000786 | Loss: 101.3978 (Pred: 94.4841, Comp: 23.0458 | Val RMSE: 166.3343 | Val MAE: 135.5215 | Val R2: 0.8141\n",
            "Epoch [164/500] | LR: 0.000784 | Loss: 94.0476 (Pred: 86.9618, Comp: 23.6191 | Val RMSE: 128.1204 | Val MAE: 102.8083 | Val R2: 0.8897\n",
            "Epoch [165/500] | LR: 0.000781 | Loss: 80.1981 (Pred: 73.1793, Comp: 23.3958 | Val RMSE: 123.1299 | Val MAE: 95.9327 | Val R2: 0.8981\n",
            "Epoch [166/500] | LR: 0.000779 | Loss: 71.0175 (Pred: 64.0572, Comp: 23.2012 | Val RMSE: 111.2241 | Val MAE: 85.4368 | Val R2: 0.9169\n",
            "Epoch [167/500] | LR: 0.000777 | Loss: 73.4330 (Pred: 66.4356, Comp: 23.3248 | Val RMSE: 117.4244 | Val MAE: 85.1008 | Val R2: 0.9074\n",
            "Epoch [168/500] | LR: 0.000774 | Loss: 73.1558 (Pred: 66.1347, Comp: 23.4037 | Val RMSE: 104.9050 | Val MAE: 74.7353 | Val R2: 0.9261\n",
            "Epoch [169/500] | LR: 0.000772 | Loss: 63.5837 (Pred: 56.6369, Comp: 23.1561 | Val RMSE: 92.4407 | Val MAE: 66.4805 | Val R2: 0.9426\n",
            "** Saved Best Model (Epoch 169) - RMSE: 92.4407 **\n",
            "Epoch [170/500] | LR: 0.000769 | Loss: 69.3685 (Pred: 62.3274, Comp: 23.4702 | Val RMSE: 111.4172 | Val MAE: 75.6097 | Val R2: 0.9166\n",
            "Epoch [171/500] | LR: 0.000767 | Loss: 71.1752 (Pred: 64.2389, Comp: 23.1208 | Val RMSE: 142.6664 | Val MAE: 105.1469 | Val R2: 0.8632\n",
            "Epoch [172/500] | LR: 0.000764 | Loss: 71.1142 (Pred: 64.1816, Comp: 23.1089 | Val RMSE: 140.8064 | Val MAE: 101.9449 | Val R2: 0.8668\n",
            "Epoch [173/500] | LR: 0.000762 | Loss: 86.1330 (Pred: 79.1856, Comp: 23.1582 | Val RMSE: 128.3642 | Val MAE: 96.9726 | Val R2: 0.8893\n",
            "Epoch [174/500] | LR: 0.000759 | Loss: 103.8255 (Pred: 96.9076, Comp: 23.0598 | Val RMSE: 124.7823 | Val MAE: 98.3516 | Val R2: 0.8954\n",
            "Epoch [175/500] | LR: 0.000757 | Loss: 77.6671 (Pred: 70.7850, Comp: 22.9403 | Val RMSE: 121.5132 | Val MAE: 92.7206 | Val R2: 0.9008\n",
            "Epoch [176/500] | LR: 0.000754 | Loss: 71.9881 (Pred: 65.0816, Comp: 23.0214 | Val RMSE: 136.3153 | Val MAE: 93.0440 | Val R2: 0.8752\n",
            "Epoch [177/500] | LR: 0.000752 | Loss: 88.8202 (Pred: 81.8458, Comp: 23.2482 | Val RMSE: 114.1494 | Val MAE: 85.2521 | Val R2: 0.9125\n",
            "Epoch [178/500] | LR: 0.000749 | Loss: 66.8324 (Pred: 59.7829, Comp: 23.4984 | Val RMSE: 131.4225 | Val MAE: 101.2229 | Val R2: 0.8840\n",
            "Epoch [179/500] | LR: 0.000747 | Loss: 83.4408 (Pred: 76.3622, Comp: 23.5951 | Val RMSE: 132.3992 | Val MAE: 94.9497 | Val R2: 0.8822\n",
            "Epoch [180/500] | LR: 0.000744 | Loss: 92.8370 (Pred: 85.8864, Comp: 23.1686 | Val RMSE: 110.8008 | Val MAE: 79.7621 | Val R2: 0.9175\n",
            "Epoch [181/500] | LR: 0.000742 | Loss: 72.9192 (Pred: 66.0438, Comp: 22.9181 | Val RMSE: 121.3062 | Val MAE: 84.5501 | Val R2: 0.9011\n",
            "Epoch [182/500] | LR: 0.000739 | Loss: 61.3980 (Pred: 54.5051, Comp: 22.9766 | Val RMSE: 133.6687 | Val MAE: 100.0287 | Val R2: 0.8800\n",
            "Epoch [183/500] | LR: 0.000736 | Loss: 93.9478 (Pred: 87.0286, Comp: 23.0642 | Val RMSE: 183.8564 | Val MAE: 135.4627 | Val R2: 0.7729\n",
            "Epoch [184/500] | LR: 0.000734 | Loss: 85.8838 (Pred: 78.9543, Comp: 23.0984 | Val RMSE: 150.4582 | Val MAE: 109.9920 | Val R2: 0.8479\n",
            "Epoch [185/500] | LR: 0.000731 | Loss: 94.0252 (Pred: 87.0748, Comp: 23.1680 | Val RMSE: 133.3335 | Val MAE: 102.1717 | Val R2: 0.8806\n",
            "Epoch [186/500] | LR: 0.000729 | Loss: 67.8407 (Pred: 60.9205, Comp: 23.0673 | Val RMSE: 110.3146 | Val MAE: 84.8441 | Val R2: 0.9182\n",
            "Epoch [187/500] | LR: 0.000726 | Loss: 67.2246 (Pred: 60.3102, Comp: 23.0482 | Val RMSE: 124.9646 | Val MAE: 85.4503 | Val R2: 0.8951\n",
            "Epoch [188/500] | LR: 0.000724 | Loss: 71.2170 (Pred: 64.3299, Comp: 22.9569 | Val RMSE: 124.2778 | Val MAE: 87.8702 | Val R2: 0.8962\n",
            "Epoch [189/500] | LR: 0.000721 | Loss: 82.4745 (Pred: 75.5809, Comp: 22.9787 | Val RMSE: 130.0342 | Val MAE: 102.0149 | Val R2: 0.8864\n",
            "Epoch [190/500] | LR: 0.000718 | Loss: 74.2864 (Pred: 67.4725, Comp: 22.7132 | Val RMSE: 125.1351 | Val MAE: 84.4451 | Val R2: 0.8948\n",
            "Epoch [191/500] | LR: 0.000716 | Loss: 64.8192 (Pred: 57.9955, Comp: 22.7459 | Val RMSE: 95.3846 | Val MAE: 72.4233 | Val R2: 0.9389\n",
            "Epoch [192/500] | LR: 0.000713 | Loss: 59.5094 (Pred: 52.7125, Comp: 22.6563 | Val RMSE: 123.0562 | Val MAE: 87.1945 | Val R2: 0.8983\n",
            "Epoch [193/500] | LR: 0.000710 | Loss: 75.1759 (Pred: 68.3715, Comp: 22.6811 | Val RMSE: 121.0509 | Val MAE: 93.3490 | Val R2: 0.9015\n",
            "Epoch [194/500] | LR: 0.000708 | Loss: 69.0548 (Pred: 62.2118, Comp: 22.8102 | Val RMSE: 115.1596 | Val MAE: 86.2345 | Val R2: 0.9109\n",
            "Epoch [195/500] | LR: 0.000705 | Loss: 74.5725 (Pred: 67.7512, Comp: 22.7379 | Val RMSE: 118.0735 | Val MAE: 88.5352 | Val R2: 0.9063\n",
            "Epoch [196/500] | LR: 0.000702 | Loss: 63.3975 (Pred: 56.5326, Comp: 22.8829 | Val RMSE: 109.4721 | Val MAE: 82.1908 | Val R2: 0.9195\n",
            "Epoch [197/500] | LR: 0.000700 | Loss: 89.8776 (Pred: 83.0140, Comp: 22.8787 | Val RMSE: 162.2169 | Val MAE: 127.3699 | Val R2: 0.8232\n",
            "Epoch [198/500] | LR: 0.000697 | Loss: 81.3245 (Pred: 74.4576, Comp: 22.8896 | Val RMSE: 139.3274 | Val MAE: 101.4874 | Val R2: 0.8696\n",
            "Epoch [199/500] | LR: 0.000694 | Loss: 91.6146 (Pred: 84.7972, Comp: 22.7246 | Val RMSE: 172.9116 | Val MAE: 123.0417 | Val R2: 0.7991\n",
            "Epoch [200/500] | LR: 0.000692 | Loss: 81.1338 (Pred: 74.2497, Comp: 22.9471 | Val RMSE: 160.5579 | Val MAE: 113.2996 | Val R2: 0.8268\n",
            "Epoch [201/500] | LR: 0.000689 | Loss: 83.9256 (Pred: 77.1230, Comp: 22.6753 | Val RMSE: 126.3133 | Val MAE: 96.0720 | Val R2: 0.8928\n",
            "Epoch [202/500] | LR: 0.000686 | Loss: 62.1718 (Pred: 55.3066, Comp: 22.8838 | Val RMSE: 117.0302 | Val MAE: 86.7608 | Val R2: 0.9080\n",
            "Epoch [203/500] | LR: 0.000684 | Loss: 67.1427 (Pred: 60.3136, Comp: 22.7639 | Val RMSE: 117.5047 | Val MAE: 74.5015 | Val R2: 0.9072\n",
            "Epoch [204/500] | LR: 0.000681 | Loss: 84.0679 (Pred: 77.2580, Comp: 22.6998 | Val RMSE: 123.0881 | Val MAE: 83.6287 | Val R2: 0.8982\n",
            "Epoch [205/500] | LR: 0.000678 | Loss: 73.9993 (Pred: 67.1451, Comp: 22.8474 | Val RMSE: 110.8501 | Val MAE: 80.8857 | Val R2: 0.9174\n",
            "Epoch [206/500] | LR: 0.000676 | Loss: 60.4634 (Pred: 53.6923, Comp: 22.5704 | Val RMSE: 106.6410 | Val MAE: 80.1938 | Val R2: 0.9236\n",
            "Epoch [207/500] | LR: 0.000673 | Loss: 73.9020 (Pred: 67.0284, Comp: 22.9119 | Val RMSE: 98.9097 | Val MAE: 67.5659 | Val R2: 0.9343\n",
            "Epoch [208/500] | LR: 0.000670 | Loss: 67.0964 (Pred: 60.2550, Comp: 22.8048 | Val RMSE: 118.3223 | Val MAE: 85.6710 | Val R2: 0.9059\n",
            "Epoch [209/500] | LR: 0.000667 | Loss: 69.8620 (Pred: 63.0840, Comp: 22.5935 | Val RMSE: 115.9508 | Val MAE: 86.3022 | Val R2: 0.9097\n",
            "Epoch [210/500] | LR: 0.000665 | Loss: 71.6363 (Pred: 64.9121, Comp: 22.4138 | Val RMSE: 129.5742 | Val MAE: 104.2911 | Val R2: 0.8872\n",
            "Epoch [211/500] | LR: 0.000662 | Loss: 102.7892 (Pred: 96.0150, Comp: 22.5806 | Val RMSE: 128.1301 | Val MAE: 93.3437 | Val R2: 0.8897\n",
            "Epoch [212/500] | LR: 0.000659 | Loss: 77.2012 (Pred: 70.3815, Comp: 22.7322 | Val RMSE: 100.9811 | Val MAE: 74.8078 | Val R2: 0.9315\n",
            "Epoch [213/500] | LR: 0.000656 | Loss: 69.7650 (Pred: 62.9615, Comp: 22.6782 | Val RMSE: 126.9210 | Val MAE: 97.7465 | Val R2: 0.8918\n",
            "Epoch [214/500] | LR: 0.000654 | Loss: 66.1602 (Pred: 59.4202, Comp: 22.4665 | Val RMSE: 103.3687 | Val MAE: 71.5545 | Val R2: 0.9282\n",
            "Epoch [215/500] | LR: 0.000651 | Loss: 73.9244 (Pred: 67.1895, Comp: 22.4495 | Val RMSE: 111.8264 | Val MAE: 82.2195 | Val R2: 0.9160\n",
            "Epoch [216/500] | LR: 0.000648 | Loss: 67.6728 (Pred: 60.8844, Comp: 22.6279 | Val RMSE: 108.5083 | Val MAE: 75.4638 | Val R2: 0.9209\n",
            "Epoch [217/500] | LR: 0.000645 | Loss: 63.5563 (Pred: 56.8301, Comp: 22.4207 | Val RMSE: 94.0270 | Val MAE: 65.8928 | Val R2: 0.9406\n",
            "Epoch [218/500] | LR: 0.000643 | Loss: 61.5249 (Pred: 54.7124, Comp: 22.7082 | Val RMSE: 113.7469 | Val MAE: 84.4445 | Val R2: 0.9131\n",
            "Epoch [219/500] | LR: 0.000640 | Loss: 60.7933 (Pred: 54.0565, Comp: 22.4561 | Val RMSE: 126.8035 | Val MAE: 96.5842 | Val R2: 0.8920\n",
            "Epoch [220/500] | LR: 0.000637 | Loss: 59.1917 (Pred: 52.4303, Comp: 22.5381 | Val RMSE: 111.8981 | Val MAE: 78.8991 | Val R2: 0.9159\n",
            "Epoch [221/500] | LR: 0.000634 | Loss: 61.6411 (Pred: 54.8818, Comp: 22.5311 | Val RMSE: 107.8002 | Val MAE: 81.3850 | Val R2: 0.9219\n",
            "Epoch [222/500] | LR: 0.000632 | Loss: 62.4968 (Pred: 55.7867, Comp: 22.3670 | Val RMSE: 93.1477 | Val MAE: 65.9391 | Val R2: 0.9417\n",
            "Epoch [223/500] | LR: 0.000629 | Loss: 63.3612 (Pred: 56.5822, Comp: 22.5967 | Val RMSE: 112.6849 | Val MAE: 80.3083 | Val R2: 0.9147\n",
            "Epoch [224/500] | LR: 0.000626 | Loss: 64.1379 (Pred: 57.4359, Comp: 22.3400 | Val RMSE: 124.1309 | Val MAE: 84.8060 | Val R2: 0.8965\n",
            "Epoch [225/500] | LR: 0.000623 | Loss: 66.6520 (Pred: 59.8443, Comp: 22.6925 | Val RMSE: 148.4751 | Val MAE: 118.3695 | Val R2: 0.8519\n",
            "Epoch [226/500] | LR: 0.000620 | Loss: 70.4303 (Pred: 63.7818, Comp: 22.1615 | Val RMSE: 113.1295 | Val MAE: 86.8023 | Val R2: 0.9140\n",
            "Epoch [227/500] | LR: 0.000618 | Loss: 86.1452 (Pred: 79.3814, Comp: 22.5462 | Val RMSE: 149.7546 | Val MAE: 105.1774 | Val R2: 0.8493\n",
            "Epoch [228/500] | LR: 0.000615 | Loss: 71.3594 (Pred: 64.7188, Comp: 22.1351 | Val RMSE: 134.6186 | Val MAE: 90.8053 | Val R2: 0.8782\n",
            "Epoch [229/500] | LR: 0.000612 | Loss: 80.2949 (Pred: 73.6407, Comp: 22.1806 | Val RMSE: 127.4376 | Val MAE: 96.7432 | Val R2: 0.8909\n",
            "Epoch [230/500] | LR: 0.000609 | Loss: 67.8650 (Pred: 61.2002, Comp: 22.2161 | Val RMSE: 160.2200 | Val MAE: 127.3351 | Val R2: 0.8275\n",
            "Epoch [231/500] | LR: 0.000606 | Loss: 87.4045 (Pred: 80.6562, Comp: 22.4942 | Val RMSE: 105.1329 | Val MAE: 74.8827 | Val R2: 0.9257\n",
            "Epoch [232/500] | LR: 0.000604 | Loss: 62.6674 (Pred: 55.9152, Comp: 22.5075 | Val RMSE: 110.6130 | Val MAE: 85.2140 | Val R2: 0.9178\n",
            "Epoch [233/500] | LR: 0.000601 | Loss: 57.9898 (Pred: 51.2178, Comp: 22.5733 | Val RMSE: 110.4784 | Val MAE: 83.4660 | Val R2: 0.9180\n",
            "Epoch [234/500] | LR: 0.000598 | Loss: 55.9103 (Pred: 49.2130, Comp: 22.3242 | Val RMSE: 131.4538 | Val MAE: 103.8470 | Val R2: 0.8839\n",
            "Epoch [235/500] | LR: 0.000595 | Loss: 81.5586 (Pred: 74.8757, Comp: 22.2760 | Val RMSE: 149.5412 | Val MAE: 109.9380 | Val R2: 0.8497\n",
            "Epoch [236/500] | LR: 0.000592 | Loss: 62.5525 (Pred: 55.8658, Comp: 22.2891 | Val RMSE: 113.3582 | Val MAE: 86.8396 | Val R2: 0.9137\n",
            "Epoch [237/500] | LR: 0.000590 | Loss: 65.2234 (Pred: 58.5300, Comp: 22.3113 | Val RMSE: 102.1853 | Val MAE: 73.0467 | Val R2: 0.9298\n",
            "Epoch [238/500] | LR: 0.000587 | Loss: 58.6172 (Pred: 51.9241, Comp: 22.3103 | Val RMSE: 114.8343 | Val MAE: 76.3578 | Val R2: 0.9114\n",
            "Epoch [239/500] | LR: 0.000584 | Loss: 57.4129 (Pred: 50.6919, Comp: 22.4031 | Val RMSE: 114.5833 | Val MAE: 88.0059 | Val R2: 0.9118\n",
            "Epoch [240/500] | LR: 0.000581 | Loss: 58.0482 (Pred: 51.4086, Comp: 22.1320 | Val RMSE: 110.2768 | Val MAE: 76.4981 | Val R2: 0.9183\n",
            "Epoch [241/500] | LR: 0.000578 | Loss: 62.7585 (Pred: 56.0757, Comp: 22.2761 | Val RMSE: 131.4657 | Val MAE: 98.5926 | Val R2: 0.8839\n",
            "Epoch [242/500] | LR: 0.000575 | Loss: 66.4944 (Pred: 59.7013, Comp: 22.6439 | Val RMSE: 100.9368 | Val MAE: 71.8604 | Val R2: 0.9315\n",
            "Epoch [243/500] | LR: 0.000573 | Loss: 67.2304 (Pred: 60.4960, Comp: 22.4480 | Val RMSE: 101.7789 | Val MAE: 75.4649 | Val R2: 0.9304\n",
            "Epoch [244/500] | LR: 0.000570 | Loss: 73.8916 (Pred: 67.1632, Comp: 22.4277 | Val RMSE: 118.4054 | Val MAE: 82.8321 | Val R2: 0.9058\n",
            "Epoch [245/500] | LR: 0.000567 | Loss: 75.0882 (Pred: 68.3721, Comp: 22.3870 | Val RMSE: 115.9072 | Val MAE: 84.1907 | Val R2: 0.9097\n",
            "Epoch [246/500] | LR: 0.000564 | Loss: 61.8810 (Pred: 55.1837, Comp: 22.3241 | Val RMSE: 102.7939 | Val MAE: 71.3403 | Val R2: 0.9290\n",
            "Epoch [247/500] | LR: 0.000561 | Loss: 66.7329 (Pred: 60.1069, Comp: 22.0867 | Val RMSE: 139.6523 | Val MAE: 101.9108 | Val R2: 0.8690\n",
            "Epoch [248/500] | LR: 0.000558 | Loss: 67.5302 (Pred: 60.9420, Comp: 21.9605 | Val RMSE: 114.8150 | Val MAE: 82.3925 | Val R2: 0.9114\n",
            "Epoch [249/500] | LR: 0.000556 | Loss: 61.6021 (Pred: 55.0250, Comp: 21.9236 | Val RMSE: 102.8257 | Val MAE: 73.3690 | Val R2: 0.9290\n",
            "Epoch [250/500] | LR: 0.000553 | Loss: 64.8900 (Pred: 58.3001, Comp: 21.9664 | Val RMSE: 144.2957 | Val MAE: 112.0060 | Val R2: 0.8601\n",
            "Epoch [251/500] | LR: 0.000550 | Loss: 72.5851 (Pred: 65.9569, Comp: 22.0942 | Val RMSE: 98.0742 | Val MAE: 70.3540 | Val R2: 0.9354\n",
            "Epoch [252/500] | LR: 0.000547 | Loss: 67.3093 (Pred: 60.6844, Comp: 22.0830 | Val RMSE: 120.4496 | Val MAE: 82.1162 | Val R2: 0.9025\n",
            "Epoch [253/500] | LR: 0.000544 | Loss: 80.5510 (Pred: 73.9649, Comp: 21.9536 | Val RMSE: 138.0476 | Val MAE: 103.8587 | Val R2: 0.8720\n",
            "Epoch [254/500] | LR: 0.000542 | Loss: 58.4624 (Pred: 51.8094, Comp: 22.1767 | Val RMSE: 103.0226 | Val MAE: 77.1765 | Val R2: 0.9287\n",
            "Epoch [255/500] | LR: 0.000539 | Loss: 61.3777 (Pred: 54.6805, Comp: 22.3239 | Val RMSE: 119.5779 | Val MAE: 81.3202 | Val R2: 0.9039\n",
            "Epoch [256/500] | LR: 0.000536 | Loss: 58.9253 (Pred: 52.2974, Comp: 22.0930 | Val RMSE: 124.4214 | Val MAE: 95.0713 | Val R2: 0.8960\n",
            "Epoch [257/500] | LR: 0.000533 | Loss: 73.8692 (Pred: 67.1593, Comp: 22.3661 | Val RMSE: 141.4665 | Val MAE: 97.5339 | Val R2: 0.8655\n",
            "Epoch [258/500] | LR: 0.000530 | Loss: 69.6354 (Pred: 62.9540, Comp: 22.2713 | Val RMSE: 128.1062 | Val MAE: 88.5035 | Val R2: 0.8897\n",
            "Epoch [259/500] | LR: 0.000527 | Loss: 65.1517 (Pred: 58.5039, Comp: 22.1592 | Val RMSE: 104.3746 | Val MAE: 75.8964 | Val R2: 0.9268\n",
            "Epoch [260/500] | LR: 0.000525 | Loss: 66.5733 (Pred: 59.9568, Comp: 22.0553 | Val RMSE: 137.3578 | Val MAE: 106.2305 | Val R2: 0.8732\n",
            "Epoch [261/500] | LR: 0.000522 | Loss: 72.7590 (Pred: 66.1736, Comp: 21.9515 | Val RMSE: 106.3986 | Val MAE: 73.0978 | Val R2: 0.9239\n",
            "Epoch [262/500] | LR: 0.000519 | Loss: 59.6945 (Pred: 53.1077, Comp: 21.9561 | Val RMSE: 102.2576 | Val MAE: 72.8380 | Val R2: 0.9297\n",
            "Epoch [263/500] | LR: 0.000516 | Loss: 67.4114 (Pred: 60.6875, Comp: 22.4131 | Val RMSE: 101.9193 | Val MAE: 77.1279 | Val R2: 0.9302\n",
            "Epoch [264/500] | LR: 0.000513 | Loss: 58.8547 (Pred: 52.1286, Comp: 22.4203 | Val RMSE: 113.5276 | Val MAE: 75.7062 | Val R2: 0.9134\n",
            "Epoch [265/500] | LR: 0.000510 | Loss: 62.6609 (Pred: 56.0601, Comp: 22.0024 | Val RMSE: 106.4748 | Val MAE: 76.6393 | Val R2: 0.9238\n",
            "Epoch [266/500] | LR: 0.000508 | Loss: 61.8451 (Pred: 55.1341, Comp: 22.3700 | Val RMSE: 124.6816 | Val MAE: 90.5873 | Val R2: 0.8956\n",
            "Epoch [267/500] | LR: 0.000505 | Loss: 67.6037 (Pred: 60.9565, Comp: 22.1574 | Val RMSE: 101.6786 | Val MAE: 75.0055 | Val R2: 0.9305\n",
            "Epoch [268/500] | LR: 0.000502 | Loss: 55.4924 (Pred: 48.7998, Comp: 22.3088 | Val RMSE: 95.2225 | Val MAE: 70.3501 | Val R2: 0.9391\n",
            "Epoch [269/500] | LR: 0.000499 | Loss: 62.8438 (Pred: 56.2519, Comp: 21.9730 | Val RMSE: 147.2968 | Val MAE: 101.8776 | Val R2: 0.8542\n",
            "Epoch [270/500] | LR: 0.000496 | Loss: 66.2279 (Pred: 59.6376, Comp: 21.9676 | Val RMSE: 105.4920 | Val MAE: 70.7571 | Val R2: 0.9252\n",
            "Epoch [271/500] | LR: 0.000494 | Loss: 69.1400 (Pred: 62.5097, Comp: 22.1011 | Val RMSE: 122.7491 | Val MAE: 93.9631 | Val R2: 0.8988\n",
            "Epoch [272/500] | LR: 0.000491 | Loss: 60.5595 (Pred: 53.9509, Comp: 22.0288 | Val RMSE: 100.2981 | Val MAE: 77.1096 | Val R2: 0.9324\n",
            "Epoch [273/500] | LR: 0.000488 | Loss: 58.9929 (Pred: 52.3128, Comp: 22.2672 | Val RMSE: 118.9931 | Val MAE: 82.8297 | Val R2: 0.9049\n",
            "Epoch [274/500] | LR: 0.000485 | Loss: 62.3955 (Pred: 55.8157, Comp: 21.9325 | Val RMSE: 107.8264 | Val MAE: 76.7341 | Val R2: 0.9219\n",
            "Epoch [275/500] | LR: 0.000482 | Loss: 57.8769 (Pred: 51.1899, Comp: 22.2899 | Val RMSE: 125.0843 | Val MAE: 83.4953 | Val R2: 0.8949\n",
            "Epoch [276/500] | LR: 0.000480 | Loss: 61.2318 (Pred: 54.6328, Comp: 21.9965 | Val RMSE: 97.4293 | Val MAE: 63.8494 | Val R2: 0.9362\n",
            "Epoch [277/500] | LR: 0.000477 | Loss: 58.7219 (Pred: 52.1016, Comp: 22.0678 | Val RMSE: 99.1546 | Val MAE: 70.8854 | Val R2: 0.9339\n",
            "Epoch [278/500] | LR: 0.000474 | Loss: 56.4900 (Pred: 49.8530, Comp: 22.1235 | Val RMSE: 108.0236 | Val MAE: 69.4514 | Val R2: 0.9216\n",
            "Epoch [279/500] | LR: 0.000471 | Loss: 63.1978 (Pred: 56.6026, Comp: 21.9841 | Val RMSE: 99.2857 | Val MAE: 73.6802 | Val R2: 0.9338\n",
            "Epoch [280/500] | LR: 0.000468 | Loss: 62.6528 (Pred: 55.9851, Comp: 22.2255 | Val RMSE: 110.8646 | Val MAE: 83.0967 | Val R2: 0.9174\n",
            "Epoch [281/500] | LR: 0.000466 | Loss: 64.9646 (Pred: 58.4000, Comp: 21.8819 | Val RMSE: 120.2726 | Val MAE: 86.2706 | Val R2: 0.9028\n",
            "Epoch [282/500] | LR: 0.000463 | Loss: 60.9448 (Pred: 54.3536, Comp: 21.9705 | Val RMSE: 111.6704 | Val MAE: 77.3908 | Val R2: 0.9162\n",
            "Epoch [283/500] | LR: 0.000460 | Loss: 67.5588 (Pred: 60.9566, Comp: 22.0073 | Val RMSE: 162.4080 | Val MAE: 129.0757 | Val R2: 0.8228\n",
            "Epoch [284/500] | LR: 0.000457 | Loss: 60.9121 (Pred: 54.2748, Comp: 22.1245 | Val RMSE: 104.3937 | Val MAE: 78.9955 | Val R2: 0.9268\n",
            "Epoch [285/500] | LR: 0.000455 | Loss: 54.1720 (Pred: 47.5028, Comp: 22.2306 | Val RMSE: 107.1609 | Val MAE: 79.0969 | Val R2: 0.9228\n",
            "Epoch [286/500] | LR: 0.000452 | Loss: 55.0687 (Pred: 48.5392, Comp: 21.7651 | Val RMSE: 101.5204 | Val MAE: 70.0483 | Val R2: 0.9308\n",
            "Epoch [287/500] | LR: 0.000449 | Loss: 50.9405 (Pred: 44.3868, Comp: 21.8460 | Val RMSE: 105.9884 | Val MAE: 81.4190 | Val R2: 0.9245\n",
            "Epoch [288/500] | LR: 0.000446 | Loss: 57.7615 (Pred: 51.2482, Comp: 21.7111 | Val RMSE: 109.0965 | Val MAE: 77.6685 | Val R2: 0.9200\n",
            "Epoch [289/500] | LR: 0.000444 | Loss: 57.5723 (Pred: 50.9585, Comp: 22.0458 | Val RMSE: 110.9385 | Val MAE: 86.3946 | Val R2: 0.9173\n",
            "Epoch [290/500] | LR: 0.000441 | Loss: 57.9078 (Pred: 51.3426, Comp: 21.8840 | Val RMSE: 103.0897 | Val MAE: 68.6880 | Val R2: 0.9286\n",
            "Epoch [291/500] | LR: 0.000438 | Loss: 65.5561 (Pred: 58.9891, Comp: 21.8902 | Val RMSE: 105.2697 | Val MAE: 75.4183 | Val R2: 0.9255\n",
            "Epoch [292/500] | LR: 0.000435 | Loss: 56.5411 (Pred: 50.0222, Comp: 21.7297 | Val RMSE: 97.6026 | Val MAE: 71.2590 | Val R2: 0.9360\n",
            "Epoch [293/500] | LR: 0.000433 | Loss: 60.5966 (Pred: 54.0814, Comp: 21.7174 | Val RMSE: 125.4142 | Val MAE: 89.0955 | Val R2: 0.8943\n",
            "Epoch [294/500] | LR: 0.000430 | Loss: 51.9051 (Pred: 45.3631, Comp: 21.8068 | Val RMSE: 97.9165 | Val MAE: 69.4699 | Val R2: 0.9356\n",
            "Epoch [295/500] | LR: 0.000427 | Loss: 56.0923 (Pred: 49.5134, Comp: 21.9296 | Val RMSE: 115.5677 | Val MAE: 79.7723 | Val R2: 0.9103\n",
            "Epoch [296/500] | LR: 0.000424 | Loss: 60.2181 (Pred: 53.5667, Comp: 22.1715 | Val RMSE: 116.2519 | Val MAE: 85.1911 | Val R2: 0.9092\n",
            "Epoch [297/500] | LR: 0.000422 | Loss: 53.9011 (Pred: 47.2869, Comp: 22.0474 | Val RMSE: 109.2899 | Val MAE: 75.7986 | Val R2: 0.9197\n",
            "Epoch [298/500] | LR: 0.000419 | Loss: 52.0590 (Pred: 45.4816, Comp: 21.9249 | Val RMSE: 105.5315 | Val MAE: 73.7607 | Val R2: 0.9252\n",
            "Epoch [299/500] | LR: 0.000416 | Loss: 54.9329 (Pred: 48.3365, Comp: 21.9882 | Val RMSE: 112.1544 | Val MAE: 76.5724 | Val R2: 0.9155\n",
            "Epoch [300/500] | LR: 0.000414 | Loss: 59.9608 (Pred: 53.4280, Comp: 21.7762 | Val RMSE: 113.4586 | Val MAE: 82.0788 | Val R2: 0.9135\n",
            "Epoch [301/500] | LR: 0.000411 | Loss: 59.6459 (Pred: 53.1106, Comp: 21.7843 | Val RMSE: 104.9090 | Val MAE: 72.2410 | Val R2: 0.9261\n",
            "Epoch [302/500] | LR: 0.000408 | Loss: 54.6506 (Pred: 48.0916, Comp: 21.8635 | Val RMSE: 111.4941 | Val MAE: 75.1095 | Val R2: 0.9165\n",
            "Epoch [303/500] | LR: 0.000406 | Loss: 62.4138 (Pred: 55.8778, Comp: 21.7866 | Val RMSE: 102.0297 | Val MAE: 76.0674 | Val R2: 0.9301\n",
            "Epoch [304/500] | LR: 0.000403 | Loss: 57.5086 (Pred: 50.9926, Comp: 21.7200 | Val RMSE: 100.0083 | Val MAE: 71.5296 | Val R2: 0.9328\n",
            "Epoch [305/500] | LR: 0.000400 | Loss: 58.3358 (Pred: 51.8220, Comp: 21.7126 | Val RMSE: 113.5565 | Val MAE: 79.4036 | Val R2: 0.9134\n",
            "Epoch [306/500] | LR: 0.000398 | Loss: 49.4820 (Pred: 42.9584, Comp: 21.7452 | Val RMSE: 92.3754 | Val MAE: 69.7446 | Val R2: 0.9427\n",
            "** Saved Best Model (Epoch 306) - RMSE: 92.3754 **\n",
            "Epoch [307/500] | LR: 0.000395 | Loss: 56.0666 (Pred: 49.5509, Comp: 21.7191 | Val RMSE: 98.4327 | Val MAE: 68.1857 | Val R2: 0.9349\n",
            "Epoch [308/500] | LR: 0.000392 | Loss: 53.7089 (Pred: 47.2021, Comp: 21.6895 | Val RMSE: 117.9453 | Val MAE: 79.9340 | Val R2: 0.9065\n",
            "Epoch [309/500] | LR: 0.000390 | Loss: 52.3247 (Pred: 45.7594, Comp: 21.8845 | Val RMSE: 109.1358 | Val MAE: 78.7466 | Val R2: 0.9200\n",
            "Epoch [310/500] | LR: 0.000387 | Loss: 55.4259 (Pred: 48.8999, Comp: 21.7535 | Val RMSE: 102.2246 | Val MAE: 75.5131 | Val R2: 0.9298\n",
            "Epoch [311/500] | LR: 0.000384 | Loss: 56.7068 (Pred: 50.0926, Comp: 22.0474 | Val RMSE: 92.2364 | Val MAE: 69.9902 | Val R2: 0.9428\n",
            "** Saved Best Model (Epoch 311) - RMSE: 92.2364 **\n",
            "Epoch [312/500] | LR: 0.000382 | Loss: 52.4315 (Pred: 45.8908, Comp: 21.8022 | Val RMSE: 95.7813 | Val MAE: 66.2026 | Val R2: 0.9384\n",
            "Epoch [313/500] | LR: 0.000379 | Loss: 49.7125 (Pred: 43.1720, Comp: 21.8015 | Val RMSE: 107.9712 | Val MAE: 83.4042 | Val R2: 0.9217\n",
            "Epoch [314/500] | LR: 0.000376 | Loss: 57.0336 (Pred: 50.5106, Comp: 21.7433 | Val RMSE: 106.1014 | Val MAE: 77.6853 | Val R2: 0.9244\n",
            "Epoch [315/500] | LR: 0.000374 | Loss: 53.9002 (Pred: 47.3730, Comp: 21.7576 | Val RMSE: 99.5654 | Val MAE: 74.2591 | Val R2: 0.9334\n",
            "Epoch [316/500] | LR: 0.000371 | Loss: 55.6975 (Pred: 49.1782, Comp: 21.7311 | Val RMSE: 101.2622 | Val MAE: 66.8713 | Val R2: 0.9311\n",
            "Epoch [317/500] | LR: 0.000369 | Loss: 56.3451 (Pred: 49.8659, Comp: 21.5975 | Val RMSE: 102.0561 | Val MAE: 74.6966 | Val R2: 0.9300\n",
            "Epoch [318/500] | LR: 0.000366 | Loss: 58.1365 (Pred: 51.6433, Comp: 21.6439 | Val RMSE: 131.6713 | Val MAE: 100.2831 | Val R2: 0.8835\n",
            "Epoch [319/500] | LR: 0.000364 | Loss: 59.3723 (Pred: 52.8197, Comp: 21.8422 | Val RMSE: 109.8338 | Val MAE: 80.4510 | Val R2: 0.9189\n",
            "Epoch [320/500] | LR: 0.000361 | Loss: 60.3594 (Pred: 53.7795, Comp: 21.9330 | Val RMSE: 104.2339 | Val MAE: 77.4975 | Val R2: 0.9270\n",
            "Epoch [321/500] | LR: 0.000358 | Loss: 62.0186 (Pred: 55.5379, Comp: 21.6023 | Val RMSE: 106.5746 | Val MAE: 72.2752 | Val R2: 0.9237\n",
            "Epoch [322/500] | LR: 0.000356 | Loss: 48.4143 (Pred: 41.9538, Comp: 21.5351 | Val RMSE: 114.0604 | Val MAE: 79.5921 | Val R2: 0.9126\n",
            "Epoch [323/500] | LR: 0.000353 | Loss: 59.7312 (Pred: 53.1896, Comp: 21.8052 | Val RMSE: 118.4893 | Val MAE: 80.0744 | Val R2: 0.9057\n",
            "Epoch [324/500] | LR: 0.000351 | Loss: 60.3610 (Pred: 53.7274, Comp: 22.1122 | Val RMSE: 100.3632 | Val MAE: 70.7441 | Val R2: 0.9323\n",
            "Epoch [325/500] | LR: 0.000348 | Loss: 56.4384 (Pred: 49.9260, Comp: 21.7079 | Val RMSE: 116.9893 | Val MAE: 88.9946 | Val R2: 0.9080\n",
            "Epoch [326/500] | LR: 0.000346 | Loss: 54.4477 (Pred: 47.9758, Comp: 21.5729 | Val RMSE: 112.6212 | Val MAE: 81.7185 | Val R2: 0.9148\n",
            "Epoch [327/500] | LR: 0.000343 | Loss: 49.4911 (Pred: 42.9707, Comp: 21.7345 | Val RMSE: 93.4114 | Val MAE: 68.4507 | Val R2: 0.9414\n",
            "Epoch [328/500] | LR: 0.000341 | Loss: 49.2842 (Pred: 42.7779, Comp: 21.6879 | Val RMSE: 97.9375 | Val MAE: 65.6898 | Val R2: 0.9356\n",
            "Epoch [329/500] | LR: 0.000338 | Loss: 53.6969 (Pred: 47.2360, Comp: 21.5363 | Val RMSE: 98.1093 | Val MAE: 71.8373 | Val R2: 0.9353\n",
            "Epoch [330/500] | LR: 0.000336 | Loss: 52.3684 (Pred: 45.7692, Comp: 21.9975 | Val RMSE: 117.7443 | Val MAE: 89.9780 | Val R2: 0.9069\n",
            "Epoch [331/500] | LR: 0.000333 | Loss: 56.5338 (Pred: 50.0109, Comp: 21.7429 | Val RMSE: 121.5729 | Val MAE: 76.6111 | Val R2: 0.9007\n",
            "Epoch [332/500] | LR: 0.000331 | Loss: 53.9271 (Pred: 47.3423, Comp: 21.9494 | Val RMSE: 104.6508 | Val MAE: 76.5326 | Val R2: 0.9264\n",
            "Epoch [333/500] | LR: 0.000328 | Loss: 58.9737 (Pred: 52.4549, Comp: 21.7294 | Val RMSE: 118.8140 | Val MAE: 86.7703 | Val R2: 0.9052\n",
            "Epoch [334/500] | LR: 0.000326 | Loss: 57.8717 (Pred: 51.4009, Comp: 21.5694 | Val RMSE: 110.2145 | Val MAE: 78.6125 | Val R2: 0.9184\n",
            "Epoch [335/500] | LR: 0.000323 | Loss: 50.0615 (Pred: 43.5771, Comp: 21.6146 | Val RMSE: 95.7113 | Val MAE: 64.9355 | Val R2: 0.9385\n",
            "Epoch [336/500] | LR: 0.000321 | Loss: 55.3673 (Pred: 48.7835, Comp: 21.9460 | Val RMSE: 99.9805 | Val MAE: 69.0812 | Val R2: 0.9328\n",
            "Epoch [337/500] | LR: 0.000319 | Loss: 53.4133 (Pred: 46.9552, Comp: 21.5270 | Val RMSE: 91.8995 | Val MAE: 63.6777 | Val R2: 0.9433\n",
            "** Saved Best Model (Epoch 337) - RMSE: 91.8995 **\n",
            "Epoch [338/500] | LR: 0.000316 | Loss: 49.6416 (Pred: 43.1544, Comp: 21.6241 | Val RMSE: 109.9256 | Val MAE: 80.7468 | Val R2: 0.9188\n",
            "Epoch [339/500] | LR: 0.000314 | Loss: 58.5705 (Pred: 52.0146, Comp: 21.8533 | Val RMSE: 106.5246 | Val MAE: 72.5664 | Val R2: 0.9238\n",
            "Epoch [340/500] | LR: 0.000311 | Loss: 57.3620 (Pred: 50.8636, Comp: 21.6615 | Val RMSE: 103.8415 | Val MAE: 70.2268 | Val R2: 0.9275\n",
            "Epoch [341/500] | LR: 0.000309 | Loss: 49.1658 (Pred: 42.6585, Comp: 21.6911 | Val RMSE: 88.5044 | Val MAE: 64.7280 | Val R2: 0.9474\n",
            "** Saved Best Model (Epoch 341) - RMSE: 88.5044 **\n",
            "Epoch [342/500] | LR: 0.000306 | Loss: 52.5718 (Pred: 46.1150, Comp: 21.5228 | Val RMSE: 97.8928 | Val MAE: 70.5571 | Val R2: 0.9356\n",
            "Epoch [343/500] | LR: 0.000304 | Loss: 53.9651 (Pred: 47.4988, Comp: 21.5545 | Val RMSE: 122.2090 | Val MAE: 85.2728 | Val R2: 0.8997\n",
            "Epoch [344/500] | LR: 0.000302 | Loss: 52.3269 (Pred: 45.8377, Comp: 21.6307 | Val RMSE: 102.1754 | Val MAE: 75.4887 | Val R2: 0.9299\n",
            "Epoch [345/500] | LR: 0.000299 | Loss: 55.7731 (Pred: 49.2661, Comp: 21.6898 | Val RMSE: 102.8699 | Val MAE: 72.7196 | Val R2: 0.9289\n",
            "Epoch [346/500] | LR: 0.000297 | Loss: 51.4606 (Pred: 44.9947, Comp: 21.5532 | Val RMSE: 96.7603 | Val MAE: 71.3439 | Val R2: 0.9371\n",
            "Epoch [347/500] | LR: 0.000295 | Loss: 47.6465 (Pred: 41.1380, Comp: 21.6950 | Val RMSE: 105.1101 | Val MAE: 68.6022 | Val R2: 0.9258\n",
            "Epoch [348/500] | LR: 0.000292 | Loss: 56.0608 (Pred: 49.5962, Comp: 21.5488 | Val RMSE: 119.7955 | Val MAE: 83.1789 | Val R2: 0.9036\n",
            "Epoch [349/500] | LR: 0.000290 | Loss: 48.8232 (Pred: 42.3805, Comp: 21.4757 | Val RMSE: 109.0534 | Val MAE: 69.4542 | Val R2: 0.9201\n",
            "Epoch [350/500] | LR: 0.000288 | Loss: 49.6811 (Pred: 43.2028, Comp: 21.5945 | Val RMSE: 94.5021 | Val MAE: 70.7961 | Val R2: 0.9400\n",
            "Epoch [351/500] | LR: 0.000285 | Loss: 51.2378 (Pred: 44.8106, Comp: 21.4242 | Val RMSE: 99.5406 | Val MAE: 69.1191 | Val R2: 0.9334\n",
            "Epoch [352/500] | LR: 0.000283 | Loss: 51.5754 (Pred: 45.1423, Comp: 21.4436 | Val RMSE: 97.7784 | Val MAE: 72.0138 | Val R2: 0.9358\n",
            "Epoch [353/500] | LR: 0.000281 | Loss: 56.8254 (Pred: 50.3674, Comp: 21.5266 | Val RMSE: 120.5519 | Val MAE: 86.1071 | Val R2: 0.9024\n",
            "Epoch [354/500] | LR: 0.000279 | Loss: 48.0695 (Pred: 41.5707, Comp: 21.6627 | Val RMSE: 108.6150 | Val MAE: 78.5592 | Val R2: 0.9207\n",
            "Epoch [355/500] | LR: 0.000276 | Loss: 49.3284 (Pred: 42.7996, Comp: 21.7627 | Val RMSE: 103.0523 | Val MAE: 69.7089 | Val R2: 0.9286\n",
            "Epoch [356/500] | LR: 0.000274 | Loss: 53.9130 (Pred: 47.4078, Comp: 21.6840 | Val RMSE: 98.6590 | Val MAE: 72.7002 | Val R2: 0.9346\n",
            "Epoch [357/500] | LR: 0.000272 | Loss: 44.4280 (Pred: 37.9829, Comp: 21.4837 | Val RMSE: 95.5008 | Val MAE: 69.5808 | Val R2: 0.9387\n",
            "Epoch [358/500] | LR: 0.000270 | Loss: 45.5361 (Pred: 39.0926, Comp: 21.4785 | Val RMSE: 112.7316 | Val MAE: 73.4235 | Val R2: 0.9146\n",
            "Epoch [359/500] | LR: 0.000268 | Loss: 57.9836 (Pred: 51.4912, Comp: 21.6413 | Val RMSE: 120.2308 | Val MAE: 89.7148 | Val R2: 0.9029\n",
            "Epoch [360/500] | LR: 0.000265 | Loss: 54.6297 (Pred: 48.0382, Comp: 21.9717 | Val RMSE: 109.1709 | Val MAE: 79.9571 | Val R2: 0.9199\n",
            "Epoch [361/500] | LR: 0.000263 | Loss: 52.4937 (Pred: 46.0804, Comp: 21.3777 | Val RMSE: 118.6694 | Val MAE: 80.3814 | Val R2: 0.9054\n",
            "Epoch [362/500] | LR: 0.000261 | Loss: 46.9068 (Pred: 40.4544, Comp: 21.5081 | Val RMSE: 93.5891 | Val MAE: 70.0353 | Val R2: 0.9411\n",
            "Epoch [363/500] | LR: 0.000259 | Loss: 47.5367 (Pred: 41.0478, Comp: 21.6294 | Val RMSE: 104.7528 | Val MAE: 72.5080 | Val R2: 0.9263\n",
            "Epoch [364/500] | LR: 0.000257 | Loss: 49.8251 (Pred: 43.3989, Comp: 21.4204 | Val RMSE: 104.3852 | Val MAE: 79.0645 | Val R2: 0.9268\n",
            "Epoch [365/500] | LR: 0.000255 | Loss: 57.1354 (Pred: 50.7431, Comp: 21.3079 | Val RMSE: 100.8163 | Val MAE: 69.8077 | Val R2: 0.9317\n",
            "Epoch [366/500] | LR: 0.000252 | Loss: 52.5888 (Pred: 46.0683, Comp: 21.7350 | Val RMSE: 114.8129 | Val MAE: 75.0024 | Val R2: 0.9114\n",
            "Epoch [367/500] | LR: 0.000250 | Loss: 54.9083 (Pred: 48.4694, Comp: 21.4628 | Val RMSE: 110.2331 | Val MAE: 76.4616 | Val R2: 0.9184\n",
            "Epoch [368/500] | LR: 0.000248 | Loss: 49.5294 (Pred: 42.9648, Comp: 21.8819 | Val RMSE: 97.8907 | Val MAE: 73.9320 | Val R2: 0.9356\n",
            "Epoch [369/500] | LR: 0.000246 | Loss: 50.5995 (Pred: 44.1236, Comp: 21.5862 | Val RMSE: 97.6160 | Val MAE: 70.4970 | Val R2: 0.9360\n",
            "Epoch [370/500] | LR: 0.000244 | Loss: 63.2364 (Pred: 56.6539, Comp: 21.9418 | Val RMSE: 93.3174 | Val MAE: 66.7820 | Val R2: 0.9415\n",
            "Epoch [371/500] | LR: 0.000242 | Loss: 52.1685 (Pred: 45.6680, Comp: 21.6685 | Val RMSE: 96.6431 | Val MAE: 68.3247 | Val R2: 0.9372\n",
            "Epoch [372/500] | LR: 0.000240 | Loss: 50.4801 (Pred: 44.0377, Comp: 21.4747 | Val RMSE: 112.8157 | Val MAE: 86.7990 | Val R2: 0.9145\n",
            "Epoch [373/500] | LR: 0.000238 | Loss: 54.5733 (Pred: 48.1059, Comp: 21.5580 | Val RMSE: 91.4374 | Val MAE: 65.1174 | Val R2: 0.9438\n",
            "Epoch [374/500] | LR: 0.000236 | Loss: 50.7124 (Pred: 44.2709, Comp: 21.4716 | Val RMSE: 99.1988 | Val MAE: 71.5315 | Val R2: 0.9339\n",
            "Epoch [375/500] | LR: 0.000234 | Loss: 54.4058 (Pred: 47.9736, Comp: 21.4406 | Val RMSE: 104.7630 | Val MAE: 71.2923 | Val R2: 0.9263\n",
            "Epoch [376/500] | LR: 0.000232 | Loss: 50.4632 (Pred: 44.0411, Comp: 21.4071 | Val RMSE: 103.4566 | Val MAE: 71.9626 | Val R2: 0.9281\n",
            "Epoch [377/500] | LR: 0.000230 | Loss: 47.2582 (Pred: 40.8250, Comp: 21.4440 | Val RMSE: 100.9986 | Val MAE: 74.4509 | Val R2: 0.9315\n",
            "Epoch [378/500] | LR: 0.000228 | Loss: 50.3466 (Pred: 43.9280, Comp: 21.3956 | Val RMSE: 105.9190 | Val MAE: 77.6270 | Val R2: 0.9246\n",
            "Epoch [379/500] | LR: 0.000226 | Loss: 49.3090 (Pred: 42.8207, Comp: 21.6279 | Val RMSE: 113.2352 | Val MAE: 77.3362 | Val R2: 0.9138\n",
            "Epoch [380/500] | LR: 0.000224 | Loss: 45.7894 (Pred: 39.3350, Comp: 21.5145 | Val RMSE: 97.3578 | Val MAE: 71.7288 | Val R2: 0.9363\n",
            "Epoch [381/500] | LR: 0.000222 | Loss: 51.3647 (Pred: 44.8818, Comp: 21.6095 | Val RMSE: 111.3063 | Val MAE: 80.0151 | Val R2: 0.9168\n",
            "Epoch [382/500] | LR: 0.000220 | Loss: 56.7440 (Pred: 50.3105, Comp: 21.4450 | Val RMSE: 98.9657 | Val MAE: 74.8935 | Val R2: 0.9342\n",
            "Epoch [383/500] | LR: 0.000218 | Loss: 52.1551 (Pred: 45.7116, Comp: 21.4784 | Val RMSE: 99.7161 | Val MAE: 70.8399 | Val R2: 0.9332\n",
            "Epoch [384/500] | LR: 0.000216 | Loss: 46.6414 (Pred: 40.2177, Comp: 21.4123 | Val RMSE: 100.4917 | Val MAE: 74.5437 | Val R2: 0.9321\n",
            "Epoch [385/500] | LR: 0.000214 | Loss: 49.7105 (Pred: 43.2228, Comp: 21.6254 | Val RMSE: 102.5511 | Val MAE: 76.0799 | Val R2: 0.9293\n",
            "Epoch [386/500] | LR: 0.000212 | Loss: 48.2949 (Pred: 41.8234, Comp: 21.5715 | Val RMSE: 100.5867 | Val MAE: 72.1965 | Val R2: 0.9320\n",
            "Epoch [387/500] | LR: 0.000211 | Loss: 45.9900 (Pred: 39.5740, Comp: 21.3864 | Val RMSE: 104.4406 | Val MAE: 75.5000 | Val R2: 0.9267\n",
            "Epoch [388/500] | LR: 0.000209 | Loss: 47.9370 (Pred: 41.4840, Comp: 21.5101 | Val RMSE: 118.1267 | Val MAE: 82.0293 | Val R2: 0.9062\n",
            "Epoch [389/500] | LR: 0.000207 | Loss: 46.6478 (Pred: 40.2339, Comp: 21.3795 | Val RMSE: 99.8936 | Val MAE: 73.9818 | Val R2: 0.9330\n",
            "Epoch [390/500] | LR: 0.000205 | Loss: 48.6818 (Pred: 42.2654, Comp: 21.3880 | Val RMSE: 111.8162 | Val MAE: 79.6054 | Val R2: 0.9160\n",
            "Epoch [391/500] | LR: 0.000203 | Loss: 50.6894 (Pred: 44.2246, Comp: 21.5493 | Val RMSE: 100.2804 | Val MAE: 72.4407 | Val R2: 0.9324\n",
            "Epoch [392/500] | LR: 0.000201 | Loss: 49.5941 (Pred: 43.1875, Comp: 21.3554 | Val RMSE: 97.3414 | Val MAE: 74.6081 | Val R2: 0.9363\n",
            "Epoch [393/500] | LR: 0.000200 | Loss: 48.8631 (Pred: 42.4609, Comp: 21.3408 | Val RMSE: 104.8499 | Val MAE: 70.3545 | Val R2: 0.9261\n",
            "Epoch [394/500] | LR: 0.000198 | Loss: 45.3123 (Pred: 38.8433, Comp: 21.5635 | Val RMSE: 109.7316 | Val MAE: 75.5384 | Val R2: 0.9191\n",
            "Epoch [395/500] | LR: 0.000196 | Loss: 46.5067 (Pred: 40.0914, Comp: 21.3845 | Val RMSE: 114.1597 | Val MAE: 84.5242 | Val R2: 0.9124\n",
            "Epoch [396/500] | LR: 0.000194 | Loss: 48.9522 (Pred: 42.4955, Comp: 21.5222 | Val RMSE: 96.4548 | Val MAE: 69.4665 | Val R2: 0.9375\n",
            "Epoch [397/500] | LR: 0.000193 | Loss: 44.9837 (Pred: 38.5687, Comp: 21.3832 | Val RMSE: 101.5987 | Val MAE: 69.0325 | Val R2: 0.9306\n",
            "Epoch [398/500] | LR: 0.000191 | Loss: 52.1540 (Pred: 45.7230, Comp: 21.4366 | Val RMSE: 104.0421 | Val MAE: 73.9781 | Val R2: 0.9273\n",
            "Epoch [399/500] | LR: 0.000189 | Loss: 53.4145 (Pred: 46.9667, Comp: 21.4926 | Val RMSE: 109.3541 | Val MAE: 73.2643 | Val R2: 0.9197\n",
            "Epoch [400/500] | LR: 0.000188 | Loss: 49.9700 (Pred: 43.5176, Comp: 21.5079 | Val RMSE: 103.9471 | Val MAE: 72.6244 | Val R2: 0.9274\n",
            "Epoch [401/500] | LR: 0.000186 | Loss: 48.2055 (Pred: 41.7614, Comp: 21.4803 | Val RMSE: 108.0818 | Val MAE: 78.7053 | Val R2: 0.9215\n",
            "Epoch [402/500] | LR: 0.000184 | Loss: 45.5892 (Pred: 39.1503, Comp: 21.4633 | Val RMSE: 94.7435 | Val MAE: 68.3636 | Val R2: 0.9397\n",
            "Epoch [403/500] | LR: 0.000183 | Loss: 52.4809 (Pred: 46.1021, Comp: 21.2625 | Val RMSE: 106.8598 | Val MAE: 72.0788 | Val R2: 0.9233\n",
            "Epoch [404/500] | LR: 0.000181 | Loss: 46.2680 (Pred: 39.8366, Comp: 21.4378 | Val RMSE: 105.0352 | Val MAE: 69.4843 | Val R2: 0.9259\n",
            "Epoch [405/500] | LR: 0.000179 | Loss: 46.1671 (Pred: 39.7826, Comp: 21.2818 | Val RMSE: 105.1183 | Val MAE: 80.5253 | Val R2: 0.9258\n",
            "Epoch [406/500] | LR: 0.000178 | Loss: 47.5613 (Pred: 41.1222, Comp: 21.4637 | Val RMSE: 96.8158 | Val MAE: 67.1816 | Val R2: 0.9370\n",
            "Epoch [407/500] | LR: 0.000176 | Loss: 45.9631 (Pred: 39.5710, Comp: 21.3069 | Val RMSE: 99.7836 | Val MAE: 71.8926 | Val R2: 0.9331\n",
            "Epoch [408/500] | LR: 0.000175 | Loss: 48.6252 (Pred: 42.1995, Comp: 21.4192 | Val RMSE: 105.6131 | Val MAE: 74.6454 | Val R2: 0.9251\n",
            "Epoch [409/500] | LR: 0.000173 | Loss: 47.7097 (Pred: 41.3339, Comp: 21.2527 | Val RMSE: 104.7939 | Val MAE: 72.4852 | Val R2: 0.9262\n",
            "Epoch [410/500] | LR: 0.000172 | Loss: 52.3746 (Pred: 45.9458, Comp: 21.4291 | Val RMSE: 110.5852 | Val MAE: 77.8618 | Val R2: 0.9178\n",
            "Epoch [411/500] | LR: 0.000170 | Loss: 49.7477 (Pred: 43.3499, Comp: 21.3261 | Val RMSE: 101.1162 | Val MAE: 68.7251 | Val R2: 0.9313\n",
            "Epoch [412/500] | LR: 0.000169 | Loss: 45.7666 (Pred: 39.3602, Comp: 21.3548 | Val RMSE: 107.4092 | Val MAE: 79.4189 | Val R2: 0.9225\n",
            "Epoch [413/500] | LR: 0.000167 | Loss: 45.1486 (Pred: 38.7432, Comp: 21.3511 | Val RMSE: 101.5822 | Val MAE: 69.8800 | Val R2: 0.9307\n",
            "Epoch [414/500] | LR: 0.000166 | Loss: 44.9341 (Pred: 38.5591, Comp: 21.2501 | Val RMSE: 117.2973 | Val MAE: 87.7602 | Val R2: 0.9076\n",
            "Epoch [415/500] | LR: 0.000164 | Loss: 48.7491 (Pred: 42.3213, Comp: 21.4260 | Val RMSE: 103.6769 | Val MAE: 67.3715 | Val R2: 0.9278\n",
            "Epoch [416/500] | LR: 0.000163 | Loss: 42.7318 (Pred: 36.3555, Comp: 21.2542 | Val RMSE: 93.2977 | Val MAE: 64.8661 | Val R2: 0.9415\n",
            "Epoch [417/500] | LR: 0.000161 | Loss: 49.3286 (Pred: 42.8929, Comp: 21.4525 | Val RMSE: 102.9114 | Val MAE: 70.8037 | Val R2: 0.9288\n",
            "Epoch [418/500] | LR: 0.000160 | Loss: 50.4087 (Pred: 43.9902, Comp: 21.3951 | Val RMSE: 106.7419 | Val MAE: 75.6623 | Val R2: 0.9234\n",
            "Epoch [419/500] | LR: 0.000158 | Loss: 46.2200 (Pred: 39.7764, Comp: 21.4784 | Val RMSE: 94.1192 | Val MAE: 68.9556 | Val R2: 0.9405\n",
            "Epoch [420/500] | LR: 0.000157 | Loss: 45.2723 (Pred: 38.8680, Comp: 21.3477 | Val RMSE: 94.8153 | Val MAE: 69.4081 | Val R2: 0.9396\n",
            "Epoch [421/500] | LR: 0.000156 | Loss: 47.6962 (Pred: 41.3029, Comp: 21.3111 | Val RMSE: 109.8982 | Val MAE: 72.8545 | Val R2: 0.9189\n",
            "Epoch [422/500] | LR: 0.000154 | Loss: 51.4905 (Pred: 45.0861, Comp: 21.3481 | Val RMSE: 100.3787 | Val MAE: 74.2821 | Val R2: 0.9323\n",
            "Epoch [423/500] | LR: 0.000153 | Loss: 48.7507 (Pred: 42.3672, Comp: 21.2783 | Val RMSE: 95.7846 | Val MAE: 70.0780 | Val R2: 0.9384\n",
            "Epoch [424/500] | LR: 0.000152 | Loss: 46.0734 (Pred: 39.5915, Comp: 21.6061 | Val RMSE: 117.8653 | Val MAE: 85.6324 | Val R2: 0.9067\n",
            "Epoch [425/500] | LR: 0.000150 | Loss: 53.7233 (Pred: 47.2640, Comp: 21.5309 | Val RMSE: 100.2928 | Val MAE: 71.8979 | Val R2: 0.9324\n",
            "Epoch [426/500] | LR: 0.000149 | Loss: 46.9185 (Pred: 40.4868, Comp: 21.4392 | Val RMSE: 101.4576 | Val MAE: 70.4396 | Val R2: 0.9308\n",
            "Epoch [427/500] | LR: 0.000148 | Loss: 46.8774 (Pred: 40.4993, Comp: 21.2606 | Val RMSE: 116.0150 | Val MAE: 74.6567 | Val R2: 0.9096\n",
            "Epoch [428/500] | LR: 0.000147 | Loss: 52.7024 (Pred: 46.2744, Comp: 21.4267 | Val RMSE: 104.2057 | Val MAE: 73.9605 | Val R2: 0.9270\n",
            "Epoch [429/500] | LR: 0.000145 | Loss: 46.3713 (Pred: 39.9883, Comp: 21.2766 | Val RMSE: 119.7601 | Val MAE: 76.4619 | Val R2: 0.9036\n",
            "Epoch [430/500] | LR: 0.000144 | Loss: 44.7302 (Pred: 38.3359, Comp: 21.3143 | Val RMSE: 96.1754 | Val MAE: 66.9615 | Val R2: 0.9379\n",
            "Epoch [431/500] | LR: 0.000143 | Loss: 45.0109 (Pred: 38.6293, Comp: 21.2721 | Val RMSE: 99.9827 | Val MAE: 69.7090 | Val R2: 0.9328\n",
            "Epoch [432/500] | LR: 0.000142 | Loss: 45.5026 (Pred: 39.0852, Comp: 21.3912 | Val RMSE: 96.2402 | Val MAE: 68.9350 | Val R2: 0.9378\n",
            "Epoch [433/500] | LR: 0.000140 | Loss: 47.8715 (Pred: 41.4564, Comp: 21.3835 | Val RMSE: 114.1633 | Val MAE: 77.6993 | Val R2: 0.9124\n",
            "Epoch [434/500] | LR: 0.000139 | Loss: 46.1186 (Pred: 39.7330, Comp: 21.2855 | Val RMSE: 108.6583 | Val MAE: 72.8873 | Val R2: 0.9207\n",
            "Epoch [435/500] | LR: 0.000138 | Loss: 44.0307 (Pred: 37.5033, Comp: 21.7580 | Val RMSE: 103.4710 | Val MAE: 74.5363 | Val R2: 0.9281\n",
            "Epoch [436/500] | LR: 0.000137 | Loss: 46.1203 (Pred: 39.7265, Comp: 21.3125 | Val RMSE: 92.1584 | Val MAE: 70.7815 | Val R2: 0.9429\n",
            "Epoch [437/500] | LR: 0.000136 | Loss: 42.6173 (Pred: 36.2542, Comp: 21.2105 | Val RMSE: 102.1645 | Val MAE: 74.0881 | Val R2: 0.9299\n",
            "Epoch [438/500] | LR: 0.000135 | Loss: 39.1061 (Pred: 32.6855, Comp: 21.4022 | Val RMSE: 96.7416 | Val MAE: 67.8295 | Val R2: 0.9371\n",
            "Epoch [439/500] | LR: 0.000134 | Loss: 46.3535 (Pred: 39.9746, Comp: 21.2629 | Val RMSE: 104.9254 | Val MAE: 75.8932 | Val R2: 0.9260\n",
            "Epoch [440/500] | LR: 0.000133 | Loss: 46.9070 (Pred: 40.4723, Comp: 21.4490 | Val RMSE: 104.3811 | Val MAE: 77.8355 | Val R2: 0.9268\n",
            "Epoch [441/500] | LR: 0.000132 | Loss: 44.4003 (Pred: 38.0320, Comp: 21.2276 | Val RMSE: 96.4682 | Val MAE: 65.2897 | Val R2: 0.9375\n",
            "Epoch [442/500] | LR: 0.000131 | Loss: 44.4480 (Pred: 38.0076, Comp: 21.4681 | Val RMSE: 91.7114 | Val MAE: 69.0557 | Val R2: 0.9435\n",
            "Epoch [443/500] | LR: 0.000130 | Loss: 44.2506 (Pred: 37.8091, Comp: 21.4716 | Val RMSE: 111.7052 | Val MAE: 76.9268 | Val R2: 0.9162\n",
            "Epoch [444/500] | LR: 0.000129 | Loss: 44.5235 (Pred: 38.1497, Comp: 21.2461 | Val RMSE: 100.0518 | Val MAE: 73.3209 | Val R2: 0.9327\n",
            "Epoch [445/500] | LR: 0.000128 | Loss: 41.9321 (Pred: 35.5647, Comp: 21.2247 | Val RMSE: 96.3797 | Val MAE: 66.7872 | Val R2: 0.9376\n",
            "Epoch [446/500] | LR: 0.000127 | Loss: 42.8140 (Pred: 36.4141, Comp: 21.3331 | Val RMSE: 108.4854 | Val MAE: 72.9802 | Val R2: 0.9209\n",
            "Epoch [447/500] | LR: 0.000126 | Loss: 47.0252 (Pred: 40.4740, Comp: 21.8372 | Val RMSE: 114.3576 | Val MAE: 79.8087 | Val R2: 0.9121\n",
            "Epoch [448/500] | LR: 0.000125 | Loss: 47.4723 (Pred: 41.0474, Comp: 21.4163 | Val RMSE: 102.9451 | Val MAE: 71.9125 | Val R2: 0.9288\n",
            "Epoch [449/500] | LR: 0.000124 | Loss: 42.9579 (Pred: 36.5433, Comp: 21.3822 | Val RMSE: 99.4529 | Val MAE: 70.7492 | Val R2: 0.9335\n",
            "Epoch [450/500] | LR: 0.000123 | Loss: 46.0337 (Pred: 39.6795, Comp: 21.1809 | Val RMSE: 97.0778 | Val MAE: 70.7221 | Val R2: 0.9367\n",
            "Epoch [451/500] | LR: 0.000122 | Loss: 46.4070 (Pred: 40.0421, Comp: 21.2162 | Val RMSE: 98.9455 | Val MAE: 69.8380 | Val R2: 0.9342\n",
            "Epoch [452/500] | LR: 0.000121 | Loss: 44.8020 (Pred: 38.3657, Comp: 21.4542 | Val RMSE: 108.5656 | Val MAE: 77.3600 | Val R2: 0.9208\n",
            "Epoch [453/500] | LR: 0.000120 | Loss: 42.8689 (Pred: 36.4758, Comp: 21.3100 | Val RMSE: 109.1443 | Val MAE: 72.1331 | Val R2: 0.9200\n",
            "Epoch [454/500] | LR: 0.000119 | Loss: 44.7844 (Pred: 38.3953, Comp: 21.2970 | Val RMSE: 103.4552 | Val MAE: 73.9113 | Val R2: 0.9281\n",
            "Epoch [455/500] | LR: 0.000119 | Loss: 40.2828 (Pred: 33.9255, Comp: 21.1910 | Val RMSE: 102.0192 | Val MAE: 68.3619 | Val R2: 0.9301\n",
            "Epoch [456/500] | LR: 0.000118 | Loss: 47.1849 (Pred: 40.7099, Comp: 21.5834 | Val RMSE: 98.8876 | Val MAE: 70.5709 | Val R2: 0.9343\n",
            "Epoch [457/500] | LR: 0.000117 | Loss: 45.8302 (Pred: 39.3852, Comp: 21.4834 | Val RMSE: 107.3614 | Val MAE: 74.8029 | Val R2: 0.9226\n",
            "Epoch [458/500] | LR: 0.000116 | Loss: 46.1791 (Pred: 39.7764, Comp: 21.3425 | Val RMSE: 97.2601 | Val MAE: 69.0197 | Val R2: 0.9364\n",
            "Epoch [459/500] | LR: 0.000116 | Loss: 43.4468 (Pred: 37.1235, Comp: 21.0777 | Val RMSE: 100.3112 | Val MAE: 73.4579 | Val R2: 0.9324\n",
            "Epoch [460/500] | LR: 0.000115 | Loss: 45.5960 (Pred: 39.1879, Comp: 21.3603 | Val RMSE: 107.9722 | Val MAE: 76.2247 | Val R2: 0.9217\n",
            "Epoch [461/500] | LR: 0.000114 | Loss: 42.8724 (Pred: 36.4841, Comp: 21.2943 | Val RMSE: 97.6171 | Val MAE: 66.5522 | Val R2: 0.9360\n",
            "Epoch [462/500] | LR: 0.000113 | Loss: 45.1349 (Pred: 38.7793, Comp: 21.1852 | Val RMSE: 105.4831 | Val MAE: 72.3443 | Val R2: 0.9252\n",
            "Epoch [463/500] | LR: 0.000113 | Loss: 46.9342 (Pred: 40.6112, Comp: 21.0767 | Val RMSE: 108.6506 | Val MAE: 75.7023 | Val R2: 0.9207\n",
            "Epoch [464/500] | LR: 0.000112 | Loss: 45.0000 (Pred: 38.6269, Comp: 21.2437 | Val RMSE: 94.0873 | Val MAE: 69.7576 | Val R2: 0.9405\n",
            "Epoch [465/500] | LR: 0.000111 | Loss: 47.5545 (Pred: 41.1191, Comp: 21.4513 | Val RMSE: 98.6604 | Val MAE: 66.9069 | Val R2: 0.9346\n",
            "Epoch [466/500] | LR: 0.000111 | Loss: 44.8605 (Pred: 38.4243, Comp: 21.4538 | Val RMSE: 101.8931 | Val MAE: 70.9865 | Val R2: 0.9302\n",
            "Epoch [467/500] | LR: 0.000110 | Loss: 47.4755 (Pred: 41.1339, Comp: 21.1389 | Val RMSE: 100.2189 | Val MAE: 68.1027 | Val R2: 0.9325\n",
            "Epoch [468/500] | LR: 0.000110 | Loss: 41.8369 (Pred: 35.4669, Comp: 21.2333 | Val RMSE: 100.9710 | Val MAE: 73.4020 | Val R2: 0.9315\n",
            "Epoch [469/500] | LR: 0.000109 | Loss: 50.2888 (Pred: 43.9081, Comp: 21.2690 | Val RMSE: 109.0829 | Val MAE: 77.6588 | Val R2: 0.9201\n",
            "Epoch [470/500] | LR: 0.000109 | Loss: 45.4811 (Pred: 39.1109, Comp: 21.2339 | Val RMSE: 93.7150 | Val MAE: 67.5903 | Val R2: 0.9410\n",
            "Epoch [471/500] | LR: 0.000108 | Loss: 46.2137 (Pred: 39.8291, Comp: 21.2819 | Val RMSE: 102.3086 | Val MAE: 75.1119 | Val R2: 0.9297\n",
            "Epoch [472/500] | LR: 0.000107 | Loss: 46.9652 (Pred: 40.6085, Comp: 21.1889 | Val RMSE: 111.9942 | Val MAE: 74.9684 | Val R2: 0.9157\n",
            "Epoch [473/500] | LR: 0.000107 | Loss: 46.2919 (Pred: 39.9193, Comp: 21.2419 | Val RMSE: 113.8235 | Val MAE: 77.9627 | Val R2: 0.9130\n",
            "Epoch [474/500] | LR: 0.000106 | Loss: 45.9178 (Pred: 39.5757, Comp: 21.1403 | Val RMSE: 96.8442 | Val MAE: 68.8465 | Val R2: 0.9370\n",
            "Epoch [475/500] | LR: 0.000106 | Loss: 41.8671 (Pred: 35.4574, Comp: 21.3658 | Val RMSE: 98.5209 | Val MAE: 69.6186 | Val R2: 0.9348\n",
            "Epoch [476/500] | LR: 0.000106 | Loss: 46.2850 (Pred: 39.7538, Comp: 21.7708 | Val RMSE: 92.6965 | Val MAE: 69.8186 | Val R2: 0.9423\n",
            "Epoch [477/500] | LR: 0.000105 | Loss: 44.7080 (Pred: 38.2657, Comp: 21.4745 | Val RMSE: 112.6214 | Val MAE: 77.0801 | Val R2: 0.9148\n",
            "Epoch [478/500] | LR: 0.000105 | Loss: 47.3328 (Pred: 41.0089, Comp: 21.0798 | Val RMSE: 97.2024 | Val MAE: 72.4879 | Val R2: 0.9365\n",
            "Epoch [479/500] | LR: 0.000104 | Loss: 42.3087 (Pred: 35.8661, Comp: 21.4753 | Val RMSE: 96.9663 | Val MAE: 69.5183 | Val R2: 0.9368\n",
            "Epoch [480/500] | LR: 0.000104 | Loss: 44.5252 (Pred: 38.1133, Comp: 21.3729 | Val RMSE: 98.5868 | Val MAE: 68.1845 | Val R2: 0.9347\n",
            "Epoch [481/500] | LR: 0.000104 | Loss: 44.5869 (Pred: 38.2416, Comp: 21.1510 | Val RMSE: 106.9929 | Val MAE: 76.9388 | Val R2: 0.9231\n",
            "Epoch [482/500] | LR: 0.000103 | Loss: 47.5443 (Pred: 41.0227, Comp: 21.7389 | Val RMSE: 104.0282 | Val MAE: 73.4771 | Val R2: 0.9273\n",
            "Epoch [483/500] | LR: 0.000103 | Loss: 46.3712 (Pred: 39.8112, Comp: 21.8666 | Val RMSE: 103.0221 | Val MAE: 69.1275 | Val R2: 0.9287\n",
            "Epoch [484/500] | LR: 0.000103 | Loss: 45.7114 (Pred: 39.2596, Comp: 21.5058 | Val RMSE: 92.4425 | Val MAE: 63.5956 | Val R2: 0.9426\n",
            "Epoch [485/500] | LR: 0.000102 | Loss: 43.8269 (Pred: 37.4407, Comp: 21.2874 | Val RMSE: 109.4022 | Val MAE: 74.1229 | Val R2: 0.9196\n",
            "Epoch [486/500] | LR: 0.000102 | Loss: 46.2813 (Pred: 39.9237, Comp: 21.1920 | Val RMSE: 95.5529 | Val MAE: 67.3927 | Val R2: 0.9387\n",
            "Epoch [487/500] | LR: 0.000102 | Loss: 42.9151 (Pred: 36.5388, Comp: 21.2544 | Val RMSE: 95.8770 | Val MAE: 70.4557 | Val R2: 0.9382\n",
            "Epoch [488/500] | LR: 0.000102 | Loss: 41.7955 (Pred: 35.4209, Comp: 21.2489 | Val RMSE: 106.0745 | Val MAE: 71.8791 | Val R2: 0.9244\n",
            "Epoch [489/500] | LR: 0.000101 | Loss: 40.2224 (Pred: 33.8405, Comp: 21.2732 | Val RMSE: 109.9127 | Val MAE: 75.0440 | Val R2: 0.9188\n",
            "Epoch [490/500] | LR: 0.000101 | Loss: 42.2779 (Pred: 35.9040, Comp: 21.2463 | Val RMSE: 96.1776 | Val MAE: 70.0901 | Val R2: 0.9378\n",
            "Epoch [491/500] | LR: 0.000101 | Loss: 45.2389 (Pred: 38.7394, Comp: 21.6652 | Val RMSE: 97.5999 | Val MAE: 72.7444 | Val R2: 0.9360\n",
            "Epoch [492/500] | LR: 0.000101 | Loss: 44.0340 (Pred: 37.6866, Comp: 21.1580 | Val RMSE: 96.1518 | Val MAE: 67.4218 | Val R2: 0.9379\n",
            "Epoch [493/500] | LR: 0.000101 | Loss: 44.5071 (Pred: 38.1238, Comp: 21.2775 | Val RMSE: 101.8073 | Val MAE: 69.1458 | Val R2: 0.9304\n",
            "Epoch [494/500] | LR: 0.000100 | Loss: 46.4680 (Pred: 40.1035, Comp: 21.2147 | Val RMSE: 100.9945 | Val MAE: 70.2329 | Val R2: 0.9315\n",
            "Epoch [495/500] | LR: 0.000100 | Loss: 47.4130 (Pred: 41.0207, Comp: 21.3076 | Val RMSE: 105.8424 | Val MAE: 78.0220 | Val R2: 0.9247\n",
            "Epoch [496/500] | LR: 0.000100 | Loss: 45.5055 (Pred: 39.1682, Comp: 21.1242 | Val RMSE: 103.9334 | Val MAE: 76.0396 | Val R2: 0.9274\n",
            "Epoch [497/500] | LR: 0.000100 | Loss: 45.9572 (Pred: 39.5600, Comp: 21.3240 | Val RMSE: 100.1625 | Val MAE: 74.9222 | Val R2: 0.9326\n",
            "Epoch [498/500] | LR: 0.000100 | Loss: 42.4630 (Pred: 36.1222, Comp: 21.1360 | Val RMSE: 107.5547 | Val MAE: 71.7989 | Val R2: 0.9223\n",
            "Epoch [499/500] | LR: 0.000100 | Loss: 42.2495 (Pred: 35.8370, Comp: 21.3751 | Val RMSE: 110.9849 | Val MAE: 76.9707 | Val R2: 0.9172\n",
            "Epoch [500/500] | LR: 0.000100 | Loss: 45.4740 (Pred: 39.1335, Comp: 21.1350 | Val RMSE: 109.1891 | Val MAE: 75.8538 | Val R2: 0.9199\n",
            "\n",
            "Saved training loss plot.\n",
            "\n",
            "Training Complete. Best Validation RMSE Achieved: 88.5044\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Main Function\n",
        "def main(train_loader, test_loader, target_scaler = None, num_epochs=200, learning_rate=1e-4, weight_decay=1e-5): # Lowered LR\n",
        "    \"\"\" Added target_scaler \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --- Configuration ---\n",
        "    FEATURE_DIM = 2048\n",
        "    NUM_COMPLETED_POINTS = 4096\n",
        "    LAMBDA_COMP = 0.3\n",
        "    # LAMBDA_GEOM = 0.1 # Disabled\n",
        "    COMP_LOSS_TYPE = 'chamfer'\n",
        "    USE_CHECKPOINTING = False # Disable checkpointing initially for easier debugging\n",
        "    GRAD_CLIP_VALUE = 0.9\n",
        "    USE_AMP = torch.cuda.is_available() # Enable Mixed Precision if CUDA is available\n",
        "\n",
        "    # --- Model ---\n",
        "    model = BioNetEnhanced(\n",
        "        feature_dim=FEATURE_DIM,\n",
        "        num_out_points=NUM_COMPLETED_POINTS,\n",
        "        use_dual_attention_vc=True,\n",
        "        use_checkpointing=USE_CHECKPOINTING\n",
        "    ).to(device)\n",
        "\n",
        "    # --- Optimizer ---\n",
        "    optimizer = Ranger(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # --- Scheduler ---\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-4)\n",
        "\n",
        "    # --- Loss Function ---\n",
        "    hybrid_loss_fn = HybridLoss(\n",
        "        lambda_comp=LAMBDA_COMP,\n",
        "        comp_loss_type=COMP_LOSS_TYPE\n",
        "    ).to(device)\n",
        "\n",
        "    # --- Mixed Precision Scaler ---\n",
        "    scaler = torch.amp.GradScaler() if USE_AMP else None\n",
        "    if USE_AMP: print(\"Using Automatic Mixed Precision (AMP).\")\n",
        "\n",
        "    # --- Augmentation ---\n",
        "    augment_fn = None\n",
        "\n",
        "    # --- Training Loop ---\n",
        "    best_rmse = float('inf')\n",
        "    train_losses, pred_losses, comp_losses = [], [], []\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        avg_loss, avg_pred, avg_comp = train_one_epoch(\n",
        "            model, train_loader, optimizer, device, hybrid_loss_fn, scaler, augment_fn, grad_clip_value=GRAD_CLIP_VALUE\n",
        "        )\n",
        "\n",
        "        # Pass scaler for denormalization during evaluation\n",
        "        mse, rmse, mae, r2 = evaluate(model, test_loader, device, target_scaler)\n",
        "\n",
        "        train_losses.append(avg_loss)\n",
        "        pred_losses.append(avg_pred)\n",
        "        comp_losses.append(avg_comp)\n",
        "        # geom_losses.append(avg_geom)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        rmse_str = f\"{rmse:.4f}\" if not np.isnan(rmse) else \"NaN\"\n",
        "        mae_str = f\"{mae:.4f}\" if not np.isnan(mae) else \"NaN\"\n",
        "        r2_str = f\"{r2:.4f}\" if not np.isnan(r2) else \"NaN\"\n",
        "        print(f\"Epoch [{epoch+1:03d}/{num_epochs:03d}] | LR: {current_lr:.6f} | \"\n",
        "              f\"Loss: {avg_loss:.4f} (Pred: {avg_pred:.4f}, Comp: {avg_comp:.4f} | \"\n",
        "              f\"Val RMSE: {rmse_str} | Val MAE: {mae_str} | Val R2: {r2_str}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if not np.isnan(rmse) and rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            try:\n",
        "                torch.save(model.state_dict(), 'best_bionet_enhanced_model.pth')\n",
        "                print(f\"** Saved Best Model (Epoch {epoch+1}) - RMSE: {rmse:.4f} **\")\n",
        "            except Exception as e: print(f\"Error saving model: {e}\")\n",
        "\n",
        "\n",
        "    # --- Plotting ---\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1); plt.plot(train_losses, label='Total Training Loss'); plt.title('Total Training Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
        "    plt.subplot(1, 2, 2); plt.plot(pred_losses, label='Prediction Loss'); plt.plot(comp_losses, label=f'Completion Loss (x{LAMBDA_COMP:.2f})'); plt.title('Training Loss Components'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    try: plt.savefig(\"training_loss_curves.png\"); print(\"\\nSaved training loss plot.\")\n",
        "    except Exception as e: print(f\"\\nError saving plot: {e}\")\n",
        "\n",
        "    best_rmse_str = f\"{best_rmse:.4f}\" if not np.isinf(best_rmse) else \"N/A\"\n",
        "    print(f\"\\nTraining Complete. Best Validation RMSE Achieved: {best_rmse_str}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    print(\"\\nStarting main training function...\")\n",
        "    NUM_EPOCHS_DEMO = 500\n",
        "    main(train_loader, test_loader, num_epochs=NUM_EPOCHS_DEMO, learning_rate=1e-3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjU1NqYAdiXU"
      },
      "source": [
        "- 88 on chamfer, lr = 1e-3, dual = true, decay=1e-5\n",
        "- 84 on chamfer, params double, lr = 1e-3, decay=1e-5, lambdacomp = 0.3, clip = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CEjFrleAZqj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc3b10c9-e320-42a5-a5b9-7c11a071852b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inferencing"
      ],
      "metadata": {
        "id": "Zso-TlbPdkXw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KukHCI6Vdrx9",
        "outputId": "bd419f1f-d5fe-430b-c319-547ac3829b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Add this cell at the end of the notebook ---\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "# Path to your folder\n",
        "folder_path = '/content/drive/MyDrive/TextFilesData'\n",
        "\n",
        "# List files in the folder to verify access\n",
        "print(os.listdir(folder_path))\n",
        "\n",
        "# Ensure all model classes (BioNetEnhanced, MultiScaleCompletionEncoder, CompletionDecoder, etc.)\n",
        "# and preprocessing functions (preprocess_point_cloud, pad_point_cloud, load_point_cloud_test)\n",
        "# are defined in the cells above this one.\n",
        "\n",
        "# --- Configuration (MUST MATCH THE TRAINED MODEL'S PARAMETERS) ---\n",
        "# --- Configuration (MUST MATCH THE TRAINED MODEL'S PARAMETERS from main()) ---\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "FEATURE_DIM_INFERENCE = 2048\n",
        "NUM_COMPLETED_POINTS_INFERENCE = 4096\n",
        "USE_DUAL_ATTENTION_VC_INFERENCE = True # From your main() function\n",
        "MAX_POINTS_PREPROCESSING = 1024\n",
        "\n",
        "print(f\"Using device for inference: {DEVICE}\")\n",
        "print(f\"Attempting to load model with FEATURE_DIM={FEATURE_DIM_INFERENCE} and NUM_COMPLETED_POINTS={NUM_COMPLETED_POINTS_INFERENCE}\")\n",
        "\n",
        "# --- 1. Instantiate the Model and Load Trained Weights ---\n",
        "print(\"Loading trained model...\")\n",
        "\n",
        "# ---- POTENTIAL MODIFICATION FOR vc_extractor.attn ----\n",
        "# If the \"Missing key(s) in state_dict: vc_extractor.attn...\" error persists\n",
        "# after correcting FEATURE_DIM and NUM_COMPLETED_POINTS, it means the\n",
        "# saved model was likely trained with use_dual_attention_vc=False.\n",
        "# Try changing use_dual_attention_vc to False here:\n",
        "USE_DUAL_ATTENTION_VC_INFERENCE = True # Start with True as in your main()\n",
        "# If loading fails, try changing to:\n",
        "# USE_DUAL_ATTENTION_VC_INFERENCE = False\n",
        "# ---- END POTENTIAL MODIFICATION ----\n",
        "\n",
        "model_inference = BioNetEnhanced(\n",
        "    feature_dim=FEATURE_DIM_INFERENCE,\n",
        "    num_out_points=NUM_COMPLETED_POINTS_INFERENCE,\n",
        "    use_dual_attention_vc=USE_DUAL_ATTENTION_VC_INFERENCE,\n",
        "    use_checkpointing=False\n",
        ").to(DEVICE)\n",
        "\n",
        "model_weights_path = '/content/best_bionet_enhanced_model.pth'\n",
        "\n",
        "if os.path.exists(model_weights_path):\n",
        "    try:\n",
        "        # Try loading with strict=False first to see which parts match\n",
        "        # This helps diagnose if the PointTransformerLayer is the remaining issue\n",
        "        print(\"Attempting to load model weights with strict=False for diagnosis...\")\n",
        "        loaded_state_dict = torch.load(model_weights_path, map_location=DEVICE)\n",
        "\n",
        "        # --- DIAGNOSIS FOR PointTransformerLayer ---\n",
        "        # The error indicates 'encoder.pt_layer.mlp.*' in checkpoint vs. 'encoder.pt_layer.pos_mlp.*', etc. in current model.\n",
        "        # This means the PointTransformerLayer definition has changed significantly.\n",
        "        # If FEATURE_DIM and NUM_COMPLETED_POINTS are correct, and use_dual_attention_vc is correct,\n",
        "        # then the PointTransformerLayer definition used for training the saved model was different\n",
        "        # from the current one in the notebook.\n",
        "        # You would need to:\n",
        "        #   1. Revert the PointTransformerLayer class definition to the one used during training.\n",
        "        #   OR\n",
        "        #   2. Retrain your model with the CURRENT PointTransformerLayer definition.\n",
        "        # Loading with strict=False will load what it can, but the pt_layer will be uninitialized/incorrect.\n",
        "        # For now, we'll proceed with strict=False for demonstration, but this part needs attention\n",
        "        # if PointTransformerLayer is indeed different.\n",
        "\n",
        "        model_inference.load_state_dict(loaded_state_dict, strict=True) # Use strict=False due to pt_layer and potentially attn\n",
        "        print(f\"Successfully loaded model weights from {model_weights_path} (potentially with some mismatches due to strict=False).\")\n",
        "        print(\"Review any 'unexpected_keys' or 'missing_keys' warnings carefully if strict=False was necessary.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model weights: {e}\")\n",
        "        print(\"Please ensure the model architecture (especially FEATURE_DIM, NUM_COMPLETED_POINTS, and submodule definitions like PointTransformerLayer) matches the saved weights, and the file path is correct.\")\n",
        "        raise\n",
        "else:\n",
        "    print(f\"ERROR: Model weights file not found at '{model_weights_path}'.\")\n",
        "    print(\"Please ensure the training was completed and the model was saved, or update the path.\")\n",
        "    raise FileNotFoundError(f\"Model weights not found: {model_weights_path}\")\n",
        "\n",
        "model_inference.eval()\n",
        "\n",
        "# --- 2. Prepare a Single Sample Point Cloud ---\n",
        "if 'df_test_point_clouds' not in globals() or df_test_point_clouds.empty:\n",
        "    print(\"ERROR: `df_test_point_clouds` DataFrame is not defined or is empty.\")\n",
        "    print(\"Please ensure the data loading and preprocessing cells have been run successfully.\")\n",
        "else:\n",
        "    sample_idx = 11 # You can change this to test different samples\n",
        "    try:\n",
        "        raw_point_cloud_data_from_df = df_test_point_clouds.iloc[sample_idx]['point_cloud']\n",
        "        original_file_path_info = df_test_point_clouds.iloc[sample_idx]['file_path']\n",
        "        print(f\"\\nProcessing sample from: {original_file_path_info}\")\n",
        "\n",
        "        preprocessed_pc_for_model = preprocess_point_cloud(raw_point_cloud_data_from_df.copy())\n",
        "        padded_pc_for_model_full = pad_point_cloud(preprocessed_pc_for_model, max_points=MAX_POINTS_PREPROCESSING)\n",
        "\n",
        "        if padded_pc_for_model_full.shape[1] > 3:\n",
        "            padded_pc_for_model_xyz = padded_pc_for_model_full[:, :3]\n",
        "        else:\n",
        "            padded_pc_for_model_xyz = padded_pc_for_model_full\n",
        "\n",
        "        input_tensor = torch.tensor(padded_pc_for_model_xyz, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "        print(f\"Shape of input tensor to the model: {input_tensor.shape}\")\n",
        "\n",
        "        print(\"Running inference to get the completed cloud...\")\n",
        "        with torch.no_grad():\n",
        "            _, completed_cloud_tensor = model_inference(input_tensor)\n",
        "\n",
        "        print(f\"Shape of raw completed_cloud_tensor: {completed_cloud_tensor.shape}\")\n",
        "\n",
        "        original_pc_to_save_numpy = padded_pc_for_model_xyz\n",
        "        completed_pc_numpy = completed_cloud_tensor.squeeze(0).cpu().numpy()\n",
        "\n",
        "        output_directory = '/content/drive/MyDrive/TextFilesData/inference_outputs/'\n",
        "        os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "        base_filename = os.path.basename(original_file_path_info)\n",
        "        if not base_filename.endswith('.txt'):\n",
        "            base_filename_stem = os.path.splitext(base_filename)[0]\n",
        "            base_filename = base_filename_stem + \".txt\"\n",
        "\n",
        "        original_output_filename = f\"original_preprocessed_{base_filename}\"\n",
        "        full_original_output_path = os.path.join(output_directory, original_output_filename)\n",
        "        np.savetxt(full_original_output_path, original_pc_to_save_numpy, fmt='%.6f', delimiter=' ')\n",
        "        print(f\"\\nPreprocessed original point cloud for model input saved to: {full_original_output_path}\")\n",
        "        print(f\"It contains {original_pc_to_save_numpy.shape[0]} points.\")\n",
        "\n",
        "        completed_output_filename = f\"completed_{base_filename}\"\n",
        "        full_completed_output_path = os.path.join(output_directory, completed_output_filename)\n",
        "        np.savetxt(full_completed_output_path, completed_pc_numpy, fmt='%.6f', delimiter=' ')\n",
        "        print(f\"Completed point cloud saved to: {full_completed_output_path}\")\n",
        "        print(f\"It contains {completed_pc_numpy.shape[0]} points.\")\n",
        "\n",
        "        print(\"\\nBoth files are in the scaled and centered coordinate space used by the model.\")\n",
        "\n",
        "    except IndexError:\n",
        "        print(f\"ERROR: Sample index {sample_idx} is out of bounds for `df_test_point_clouds` (size: {len(df_test_point_clouds)}).\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during single sample processing: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ip_0ylcdm3j",
        "outputId": "67d9e329-68c3-462e-edd1-bef8d337a01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['20191002', '20190828', 'test_list.txt', 'train_list.txt', 'gcn_model_weights_0.001epoch50.pth', 'model2_weights.pth', 'model3_weights.pth', 'model4_weights.pth', 'pointNet_weights.pth', 'pointNet2_weights.pth', 'pointNet3_weights.pth', 'pointNet4_weights.pth']\n",
            "Using device for inference: cuda\n",
            "Attempting to load model with FEATURE_DIM=2048 and NUM_COMPLETED_POINTS=4096\n",
            "Loading trained model...\n",
            "Attempting to load model weights with strict=False for diagnosis...\n",
            "Successfully loaded model weights from /content/best_bionet_enhanced_model.pth (potentially with some mismatches due to strict=False).\n",
            "Review any 'unexpected_keys' or 'missing_keys' warnings carefully if strict=False was necessary.\n",
            "\n",
            "Processing sample from: /content/drive/My Drive/TextFilesData/20190828/Tonye-w_20190828_003/3-16-1-b.txt\n",
            "Shape of input tensor to the model: torch.Size([1, 1024, 3])\n",
            "Running inference to get the completed cloud...\n",
            "Shape of raw completed_cloud_tensor: torch.Size([1, 4096, 3])\n",
            "\n",
            "Preprocessed original point cloud for model input saved to: /content/drive/MyDrive/TextFilesData/inference_outputs/original_preprocessed_3-16-1-b.txt\n",
            "It contains 1024 points.\n",
            "Completed point cloud saved to: /content/drive/MyDrive/TextFilesData/inference_outputs/completed_3-16-1-b.txt\n",
            "It contains 4096 points.\n",
            "\n",
            "Both files are in the scaled and centered coordinate space used by the model.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}